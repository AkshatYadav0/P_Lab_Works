
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Transformers &#8212; Lab Works</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="GRU + Attention" href="attention_2.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Lab Works</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Home
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="attention_2.html">
   GRU + Attention
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Transformers
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/AkshatYadav0/P_Lab/master?urlpath=tree/Transformers.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/AkshatYadav0/P_Lab"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/AkshatYadav0/P_Lab/issues/new?title=Issue%20on%20page%20%2FTransformers.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/Transformers.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#overview">
   Overview
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-organization">
   Data Organization
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#modelling">
   Modelling
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#positional-encodings">
     Positional Encodings
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#self-attention">
     Self Attention
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multi-head-attention">
     Multi Head Attention
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#feed-forward">
     Feed Forward
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#transformer-block">
     Transformer Block
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complied-model-no-poe">
     Complied Model (No PoE)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complied-model-with-poe">
     Complied Model (with PoE)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-no-poe">
   Training (No PoE)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Multi-Head Attention
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#single-head-attention">
     Single-Head Attention
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#testing-no-poe">
   Testing (No PoE)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     Multi-Head Attention
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     Single-Head Attention
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-with-poe">
   Training (with PoE)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     Multi-Head Attention
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     Single-Head Attention
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#testing-with-poe">
   Testing (with PoE)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multi-head">
     Multi-Head
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#single-head">
     Single-Head
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Transformers</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#overview">
   Overview
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-organization">
   Data Organization
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#modelling">
   Modelling
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#positional-encodings">
     Positional Encodings
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#self-attention">
     Self Attention
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multi-head-attention">
     Multi Head Attention
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#feed-forward">
     Feed Forward
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#transformer-block">
     Transformer Block
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complied-model-no-poe">
     Complied Model (No PoE)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complied-model-with-poe">
     Complied Model (with PoE)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-no-poe">
   Training (No PoE)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Multi-Head Attention
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#single-head-attention">
     Single-Head Attention
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#testing-no-poe">
   Testing (No PoE)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     Multi-Head Attention
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     Single-Head Attention
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-with-poe">
   Training (with PoE)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     Multi-Head Attention
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     Single-Head Attention
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#testing-with-poe">
   Testing (with PoE)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multi-head">
     Multi-Head
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#single-head">
     Single-Head
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="transformers">
<h1>Transformers<a class="headerlink" href="#transformers" title="Permalink to this headline">#</a></h1>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">#</a></h2>
<p><strong>This notebook implements Transformer model for HCP (movie watching) data</strong></p>
<p>Transformers were first present by Vaswani, et al. in their paper <a class="reference external" href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a>.</p>
</section>
<hr class="docutils" />
<section id="data-organization">
<h2>Data Organization<a class="headerlink" href="#data-organization" title="Permalink to this headline">#</a></h2>
<p>Same as in the <a class="reference external" href="https://akshatyadav0.github.io/P_Lab_Works/attention_2.html">gru + attention</a> notebook</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;Data/HCP_movie_watching.pkl&#39;</span><span class="p">,</span><span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">TS</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">TS</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dict_keys([&#39;testretest&#39;, &#39;twomen&#39;, &#39;bridgeville&#39;, &#39;pockets&#39;, &#39;overcome&#39;, &#39;inception&#39;, &#39;socialnet&#39;, &#39;oceans&#39;, &#39;flower&#39;, &#39;hotel&#39;, &#39;garden&#39;, &#39;dreary&#39;, &#39;homealone&#39;, &#39;brokovich&#39;, &#39;starwars&#39;])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rel</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">l</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">movie_name</span><span class="p">,</span> <span class="n">ts</span> <span class="ow">in</span> <span class="n">TS</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">l</span>
    <span class="n">l</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">movie_name</span><span class="p">,</span> <span class="n">ts</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>testretest (4, 176, 84, 300)
twomen (176, 245, 300)
bridgeville (176, 222, 300)
pockets (176, 189, 300)
overcome (176, 65, 300)
inception (176, 227, 300)
socialnet (176, 260, 300)
oceans (176, 250, 300)
flower (176, 181, 300)
hotel (176, 186, 300)
garden (176, 205, 300)
dreary (176, 143, 300)
homealone (176, 233, 300)
brokovich (176, 231, 300)
starwars (176, 256, 300)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_feature</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_feature</span>  <span class="o">=</span> <span class="p">[]</span>
<span class="n">train_target</span>  <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_target</span>   <span class="o">=</span> <span class="p">[]</span>
<span class="n">seq_length</span>    <span class="o">=</span> <span class="mi">198</span>

<span class="k">for</span> <span class="n">movie_name</span><span class="p">,</span> <span class="n">ts</span> <span class="ow">in</span> <span class="n">TS</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">pep</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">movie_name</span> <span class="o">!=</span> <span class="s2">&quot;testretest&quot;</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ts</span><span class="p">:</span>
            <span class="n">pep</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">pep</span> <span class="o">&lt;=</span> <span class="mi">100</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">&gt;</span><span class="n">seq_length</span><span class="p">:</span>
                    <span class="n">k</span> <span class="o">=</span> <span class="n">i</span><span class="p">[:</span><span class="n">seq_length</span><span class="p">][:]</span>
                    <span class="n">train_feature</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
                    <span class="n">train_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">])</span>
                    
                    <span class="n">k</span> <span class="o">=</span> <span class="n">i</span><span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="n">seq_length</span><span class="p">:][:]</span>
                    <span class="n">train_feature</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
                    <span class="n">train_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">])</span>
                
                <span class="k">elif</span> <span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">&lt;</span><span class="n">seq_length</span><span class="p">:</span>
                    <span class="n">k</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">300</span><span class="p">]</span><span class="o">*</span><span class="n">seq_length</span>
                    <span class="n">k</span><span class="p">[</span><span class="n">seq_length</span><span class="o">-</span><span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:]</span> <span class="o">=</span> <span class="n">i</span>
                    <span class="n">train_feature</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
                    <span class="n">train_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">train_feature</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                    <span class="n">train_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">])</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">&gt;</span><span class="n">seq_length</span><span class="p">:</span>
                    <span class="n">k</span> <span class="o">=</span> <span class="n">i</span><span class="p">[:</span><span class="n">seq_length</span><span class="p">][:]</span>
                    <span class="n">test_feature</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
                    <span class="n">test_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">])</span>
                   
                    <span class="n">k</span> <span class="o">=</span> <span class="n">i</span><span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="n">seq_length</span><span class="p">:][:]</span>
                    <span class="n">test_feature</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
                    <span class="n">test_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">])</span>
                
                <span class="k">elif</span> <span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">&lt;</span><span class="n">seq_length</span><span class="p">:</span>
                    <span class="n">k</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">300</span><span class="p">]</span><span class="o">*</span><span class="n">seq_length</span>
                    <span class="n">k</span><span class="p">[</span><span class="n">seq_length</span><span class="o">-</span><span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:]</span> <span class="o">=</span> <span class="n">i</span>
                    <span class="n">test_feature</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
                    <span class="n">test_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">test_feature</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                    <span class="n">test_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">pep</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">jj</span> <span class="ow">in</span> <span class="n">ts</span><span class="p">:</span>
            <span class="n">pep</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">jj</span><span class="p">:</span>
                <span class="n">pep</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">pep</span> <span class="o">&lt;=</span> <span class="mi">101</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">&gt;</span><span class="n">seq_length</span><span class="p">:</span>
                        <span class="n">k</span> <span class="o">=</span> <span class="n">i</span><span class="p">[:</span><span class="n">seq_length</span><span class="p">][:]</span>
                        <span class="n">train_feature</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
                        <span class="n">train_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">])</span>

                        <span class="n">k</span> <span class="o">=</span> <span class="n">i</span><span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="n">seq_length</span><span class="p">:][:]</span>
                        <span class="n">train_feature</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
                        <span class="n">train_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">])</span>

                    <span class="k">elif</span> <span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">&lt;</span><span class="n">seq_length</span><span class="p">:</span>
                        <span class="n">k</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">300</span><span class="p">]</span><span class="o">*</span><span class="n">seq_length</span>
                        <span class="n">k</span><span class="p">[</span><span class="n">seq_length</span><span class="o">-</span><span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:]</span> <span class="o">=</span> <span class="n">i</span>
                        <span class="n">train_feature</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
                        <span class="n">train_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">])</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">train_feature</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                        <span class="n">train_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">])</span>

                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">&gt;</span><span class="n">seq_length</span><span class="p">:</span>
                        <span class="n">k</span> <span class="o">=</span> <span class="n">i</span><span class="p">[:</span><span class="n">seq_length</span><span class="p">][:]</span>
                        <span class="n">test_feature</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
                        <span class="n">test_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">])</span>

                        <span class="n">k</span> <span class="o">=</span> <span class="n">i</span><span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="n">seq_length</span><span class="p">:][:]</span>
                        <span class="n">test_feature</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
                        <span class="n">test_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">])</span>

                    <span class="k">elif</span> <span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">&lt;</span><span class="n">seq_length</span><span class="p">:</span>
                        <span class="n">k</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">300</span><span class="p">]</span><span class="o">*</span><span class="n">seq_length</span>
                        <span class="n">k</span><span class="p">[</span><span class="n">seq_length</span><span class="o">-</span><span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:]</span> <span class="o">=</span> <span class="n">i</span>
                        <span class="n">test_feature</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
                        <span class="n">test_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">])</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">test_feature</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                        <span class="n">test_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">])</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">pep</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>176
176
176
176
176
176
176
176
176
176
176
176
176
176
176
176
176
176
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">TensorDataset</span><span class="p">,</span> <span class="n">DataLoader</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_feature</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_target</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
<span class="n">test_data</span>  <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_feature</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_target</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data.sampler</span> <span class="kn">import</span> <span class="n">SubsetRandomSampler</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">valid_data</span>  <span class="o">=</span> <span class="mf">0.25</span>
<span class="n">t_train</span>     <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
<span class="n">data_no</span>     <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">t_train</span><span class="p">))</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">data_no</span><span class="p">)</span>
<span class="n">split_no</span>    <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">valid_data</span><span class="o">*</span><span class="n">t_train</span><span class="p">))</span>
<span class="n">train</span><span class="p">,</span><span class="n">valid</span> <span class="o">=</span> <span class="n">data_no</span><span class="p">[</span><span class="n">split_no</span><span class="p">:],</span><span class="n">data_no</span><span class="p">[:</span><span class="n">split_no</span><span class="p">]</span>

<span class="n">train_sampler</span> <span class="o">=</span> <span class="n">SubsetRandomSampler</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
<span class="n">valid_sampler</span> <span class="o">=</span> <span class="n">SubsetRandomSampler</span><span class="p">(</span><span class="n">valid</span><span class="p">)</span>

<span class="n">train_loader</span>  <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span><span class="n">sampler</span><span class="o">=</span><span class="n">train_sampler</span><span class="p">,</span><span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">valid_loader</span>  <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span><span class="n">sampler</span><span class="o">=</span><span class="n">valid_sampler</span><span class="p">,</span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span><span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">test_loader</span>   <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span><span class="n">shuffle</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">is_cuda</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>

<span class="k">if</span> <span class="n">is_cuda</span><span class="p">:</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">device</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>device(type=&#39;cuda&#39;)
</pre></div>
</div>
</div>
</div>
</section>
<section id="modelling">
<h2>Modelling<a class="headerlink" href="#modelling" title="Permalink to this headline">#</a></h2>
<section id="positional-encodings">
<h3>Positional Encodings<a class="headerlink" href="#positional-encodings" title="Permalink to this headline">#</a></h3>
<img alt="_images/po_enc.png" src="_images/po_enc.png" />
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">PositionalEncoding</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">d_model</span><span class="p">,</span><span class="n">seq_len</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            seq_len: length of input sequence</span>
<span class="sd">            d_model: demension of encoding</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PositionalEncoding</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span> <span class="o">=</span> <span class="n">seq_len</span>
        <span class="n">pe</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">seq_len</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">pos</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">seq_len</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span><span class="mi">2</span><span class="p">):</span>
                <span class="n">pe</span><span class="p">[</span><span class="n">pos</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">pos</span> <span class="o">/</span> <span class="p">(</span><span class="mi">10000</span> <span class="o">**</span> <span class="p">((</span><span class="mi">2</span> <span class="o">*</span> <span class="n">i</span><span class="p">)</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">)))</span>
                <span class="n">pe</span><span class="p">[</span><span class="n">pos</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">pos</span> <span class="o">/</span> <span class="p">(</span><span class="mi">10000</span> <span class="o">**</span> <span class="p">((</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">)))</span>
        <span class="n">pe</span> <span class="o">=</span> <span class="n">pe</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;pe&#39;</span><span class="p">,</span> <span class="n">pe</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pe</span><span class="p">[:,:</span><span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="self-attention">
<h3>Self Attention<a class="headerlink" href="#self-attention" title="Permalink to this headline">#</a></h3>
<img alt="_images/scale_dot_product_attention.jpg" src="_images/scale_dot_product_attention.jpg" />
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Attention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    q : current sequence</span>
<span class="sd">    k : every sequence to check relationship with Qeury</span>
<span class="sd">    v : every seq same with Key</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Attention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>     <span class="c1"># [batch_size, head, length, d_tensor]</span>
        
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">head</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">d_tensor</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>

        <span class="c1"># 1. dot product Query with Key^T to compute similarity</span>
        
        <span class="n">k_t</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="p">(</span><span class="n">q</span> <span class="o">@</span> <span class="n">k_t</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">d_tensor</span><span class="p">)</span>  <span class="c1"># scaled dot product</span>

        <span class="c1"># 2. Masking (opt)</span>
        
        <span class="c1"># 3. Softmax</span>
        <span class="n">score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>

        <span class="c1"># 4. multiply with Value</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">score</span> <span class="o">@</span> <span class="n">v</span>

        <span class="k">return</span> <span class="n">v</span><span class="p">,</span> <span class="n">score</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="multi-head-attention">
<h3>Multi Head Attention<a class="headerlink" href="#multi-head-attention" title="Permalink to this headline">#</a></h3>
<img alt="_images/multi_head_attention.jpg" src="_images/multi_head_attention.jpg" />
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MultiHeadAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">n_head</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MultiHeadAttention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_head</span> <span class="o">=</span> <span class="n">n_head</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">Attention</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w_q</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w_k</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w_v</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w_concat</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        
        <span class="c1"># 1. dot product with weight matrices</span>
        <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_q</span><span class="p">(</span><span class="n">q</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_k</span><span class="p">(</span><span class="n">k</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_v</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

        <span class="c1"># 2. split tensor by number of heads</span>
        <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">q</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">k</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

        <span class="c1"># 3. do scale dot product to compute similarity</span>
        <span class="n">out</span><span class="p">,</span> <span class="n">attention</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span><span class="c1">#, mask=mask)</span>
        
        <span class="c1"># 4. concat and pass to linear layer</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_concat</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="c1"># visualize attention map =&gt; may implement visualization</span>
        
        <span class="k">return</span> <span class="n">out</span>

    <span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        split tensor by number of head</span>
<span class="sd">        </span>
<span class="sd">        :param tensor: [batch_size, length, d_model]</span>
<span class="sd">        :return: [batch_size, head, length, d_tensor]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">d_model</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>

        <span class="n">d_tensor</span> <span class="o">=</span> <span class="n">d_model</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_head</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_head</span><span class="p">,</span> <span class="n">d_tensor</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">tensor</span>

    <span class="k">def</span> <span class="nf">concat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param tensor: [batch_size, head, length, d_tensor]</span>
<span class="sd">        :return: [batch_size, length, d_model]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">head</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">d_tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
        <span class="n">d_model</span> <span class="o">=</span> <span class="n">head</span> <span class="o">*</span> <span class="n">d_tensor</span>

        <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensor</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="feed-forward">
<h3>Feed Forward<a class="headerlink" href="#feed-forward" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">FeedForward</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">feed_fwd</span><span class="p">,</span> <span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span> 
        
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">feed_fwd</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">feed_fwd</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="transformer-block">
<h3>Transformer Block<a class="headerlink" href="#transformer-block" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">TransformerBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span><span class="n">feed_fwd</span> <span class="p">,</span><span class="n">n_heads</span><span class="p">,</span><span class="n">drop_prob</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TransformerBlock</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">           embed_dim: dimension of the embedding</span>
<span class="sd">           n_heads: number of attention heads</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_head</span><span class="o">=</span><span class="n">n_head</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">feed_fwd</span> <span class="o">=</span> <span class="n">FeedForward</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span> <span class="n">feed_fwd</span><span class="o">=</span><span class="n">feed_fwd</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">drop_prob</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">drop_prob</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">drop_prob</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span><span class="c1">#key,query,value):</span>
        
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">           key: key vector</span>
<span class="sd">           query: query vector</span>
<span class="sd">           value: value vector</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="c1"># 1. compute self attention</span>
        <span class="n">_x</span> <span class="o">=</span> <span class="n">x</span>
        <span class="c1">#print(x.shape)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
        
        <span class="c1"># 2. add and norm</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">_x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="c1"># 3. feed forward network</span>
        <span class="n">_x</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feed_fwd</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
      
        <span class="c1"># 4. add and norm</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">_x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="complied-model-no-poe">
<h3>Complied Model (No PoE)<a class="headerlink" href="#complied-model-no-poe" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Transformer_Model</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">feed_fwd</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">n_head</span><span class="p">,</span> <span class="n">drop_prob</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Transformer_Model</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">TransformerBlock</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">feed_fwd</span><span class="p">,</span> <span class="n">n_head</span><span class="p">,</span> <span class="n">drop_prob</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">)])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span><span class="n">out_dim</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_out</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="complied-model-with-poe">
<h3>Complied Model (with PoE)<a class="headerlink" href="#complied-model-with-poe" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Transformer_Model_PoE</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">feed_fwd</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">n_head</span><span class="p">,</span> <span class="n">drop_prob</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Transformer_Model_PoE</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">po_en</span> <span class="o">=</span> <span class="n">PositionalEncoding</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span><span class="n">seq_len</span><span class="o">=</span><span class="mi">198</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">TransformerBlock</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">feed_fwd</span><span class="p">,</span> <span class="n">n_head</span><span class="p">,</span> <span class="n">drop_prob</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">)])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span><span class="n">out_dim</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">po_en</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_out</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="training-no-poe">
<h2>Training (No PoE)<a class="headerlink" href="#training-no-poe" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span><span class="n">train_loader</span><span class="p">,</span><span class="n">net</span><span class="p">,</span><span class="n">valid_loader</span><span class="p">,</span><span class="n">optimzer</span><span class="p">,</span><span class="n">criterion</span><span class="p">,</span><span class="n">att_name</span><span class="p">):</span>
    <span class="n">val_acc</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">tr_acc</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="n">clip</span> <span class="o">=</span> <span class="mi">3</span> <span class="c1"># gradient clipping</span>

    <span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    
    <span class="n">valid_loss_min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">Inf</span> 
    
    <span class="n">valid_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">train_losses</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">num_correct</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">train_loss</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">valid_loss</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">train_acc</span>  <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">valid_acc</span>  <span class="o">=</span> <span class="mf">0.0</span> 
        <span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
            
            <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">net</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">inputs</span><span class="p">)[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
            <span class="c1">#print(output[:, -1, :].shape)</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span> 
            
            <span class="n">top_value</span><span class="p">,</span> <span class="n">top_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
            
            <span class="n">correct_tensor</span> <span class="o">=</span> <span class="n">top_index</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">top_index</span><span class="p">))</span>
            <span class="n">correct</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">correct_tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            <span class="n">num_correct</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">)</span>


            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">clip</span><span class="p">)</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">train_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">tr_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">num_correct</span><span class="o">/</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">batch_size</span><span class="p">))</span>

        <span class="n">acc</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">val_losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">num_correct</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">v_c</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">valid_loader</span><span class="p">:</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="n">output</span><span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">inputs</span><span class="p">)[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
            
            <span class="n">pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span> 
            <span class="n">top_value</span><span class="p">,</span> <span class="n">top_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">correct_tensor</span> <span class="o">=</span> <span class="n">top_index</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">top_index</span><span class="p">))</span>
            <span class="n">correct</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">correct_tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            <span class="n">num_correct</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">)</span>

            <span class="n">val_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span><span class="n">labels</span><span class="p">)</span>
            <span class="n">val_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            
            <span class="k">if</span> <span class="n">val_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">valid_loss_min</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation loss decreased (</span><span class="si">{:.6f}</span><span class="s1"> --&gt; </span><span class="si">{:.6f}</span><span class="s1">).  Saving model ...&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">valid_loss_min</span><span class="p">,</span> <span class="n">val_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>
                <span class="n">best_epoch</span> <span class="o">=</span> <span class="n">e</span>
                <span class="c1">#if att:</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">att_name</span><span class="si">}</span><span class="s1">.pt&#39;</span><span class="p">)</span>
                <span class="c1">#else:</span>
                <span class="c1">#    torch.save(net.state_dict(), &#39;Trns_Single_Att.pt&#39;)</span>
                <span class="n">valid_loss_min</span> <span class="o">=</span> <span class="n">val_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="n">net</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">valid_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">val_losses</span><span class="p">))</span>
        <span class="n">train_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_loss</span><span class="p">))</span>
        <span class="n">val_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">num_correct</span><span class="o">/</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">valid_loader</span><span class="p">)</span><span class="o">*</span><span class="n">batch_size</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch: </span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1"> </span><span class="se">\t</span><span class="s1">Training Loss: </span><span class="si">{:.6f}</span><span class="s1"> </span><span class="se">\t</span><span class="s1">Validation Loss: </span><span class="si">{:.6f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">e</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">epochs</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_loss</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">val_losses</span><span class="p">)))</span>
    
    <span class="k">return</span> <span class="n">train_losses</span><span class="p">,</span><span class="n">valid_losses</span><span class="p">,</span><span class="n">tr_acc</span><span class="p">,</span><span class="n">val_acc</span><span class="p">,</span><span class="n">best_epoch</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">epochs</span>     <span class="o">=</span> <span class="mi">100</span>
<span class="n">d_model</span>    <span class="o">=</span> <span class="mi">300</span>
<span class="n">feed_fwd</span>   <span class="o">=</span> <span class="mi">150</span>
<span class="n">output_dim</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">n_head</span>     <span class="o">=</span> <span class="mi">4</span>
<span class="n">n_layers</span>   <span class="o">=</span> <span class="mi">2</span>
<span class="n">drop_prob</span>  <span class="o">=</span> <span class="mf">0.0006</span>
<span class="n">lr</span>         <span class="o">=</span> <span class="mf">0.001</span>
</pre></div>
</div>
</div>
</div>
<section id="id1">
<h3>Multi-Head Attention<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Transformer_Model</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">feed_fwd</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span><span class="n">n_head</span><span class="p">,</span> <span class="n">drop_prob</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">model</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Transformer_Model(
  (layers): ModuleList(
    (0): TransformerBlock(
      (attention): MultiHeadAttention(
        (attention): Attention(
          (softmax): Softmax(dim=-1)
        )
        (w_q): Linear(in_features=300, out_features=300, bias=True)
        (w_k): Linear(in_features=300, out_features=300, bias=True)
        (w_v): Linear(in_features=300, out_features=300, bias=True)
        (w_concat): Linear(in_features=300, out_features=300, bias=True)
      )
      (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)
      (feed_fwd): FeedForward(
        (l1): Linear(in_features=300, out_features=150, bias=True)
        (l2): Linear(in_features=150, out_features=300, bias=True)
        (dropout): Dropout(p=0.0006, inplace=False)
        (relu): ReLU()
      )
      (dropout1): Dropout(p=0.0006, inplace=False)
      (dropout2): Dropout(p=0.0006, inplace=False)
    )
    (1): TransformerBlock(
      (attention): MultiHeadAttention(
        (attention): Attention(
          (softmax): Softmax(dim=-1)
        )
        (w_q): Linear(in_features=300, out_features=300, bias=True)
        (w_k): Linear(in_features=300, out_features=300, bias=True)
        (w_v): Linear(in_features=300, out_features=300, bias=True)
        (w_concat): Linear(in_features=300, out_features=300, bias=True)
      )
      (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)
      (feed_fwd): FeedForward(
        (l1): Linear(in_features=300, out_features=150, bias=True)
        (l2): Linear(in_features=150, out_features=300, bias=True)
        (dropout): Dropout(p=0.0006, inplace=False)
        (relu): ReLU()
      )
      (dropout1): Dropout(p=0.0006, inplace=False)
      (dropout2): Dropout(p=0.0006, inplace=False)
    )
  )
  (linear_out): Linear(in_features=300, out_features=15, bias=True)
)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_losses</span><span class="p">,</span><span class="n">valid_losses</span><span class="p">,</span><span class="n">tr_acc</span><span class="p">,</span><span class="n">val_acc</span><span class="p">,</span><span class="n">best_epoch</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span><span class="n">train_loader</span><span class="p">,</span><span class="n">model</span><span class="p">,</span><span class="n">valid_loader</span><span class="p">,</span><span class="n">optimizer</span><span class="p">,</span><span class="n">criterion</span><span class="p">,</span><span class="n">att_name</span> <span class="o">=</span> <span class="s2">&quot;Multi_Att&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Validation loss decreased (inf --&gt; 0.707668).  Saving model ...
Validation loss decreased (0.707668 --&gt; 0.655770).  Saving model ...
Validation loss decreased (0.655770 --&gt; 0.531409).  Saving model ...
Validation loss decreased (0.531409 --&gt; 0.510596).  Saving model ...
Validation loss decreased (0.510596 --&gt; 0.306049).  Saving model ...
Epoch: 1/100 	Training Loss: 1.163735 	Validation Loss: 0.622722
Validation loss decreased (0.306049 --&gt; 0.220421).  Saving model ...
Validation loss decreased (0.220421 --&gt; 0.209363).  Saving model ...
Epoch: 2/100 	Training Loss: 0.386537 	Validation Loss: 0.424249
Validation loss decreased (0.209363 --&gt; 0.119314).  Saving model ...
Validation loss decreased (0.119314 --&gt; 0.091067).  Saving model ...
Validation loss decreased (0.091067 --&gt; 0.059783).  Saving model ...
Epoch: 3/100 	Training Loss: 0.189346 	Validation Loss: 0.397704
Epoch: 4/100 	Training Loss: 0.124512 	Validation Loss: 0.400787
Epoch: 5/100 	Training Loss: 0.075158 	Validation Loss: 0.328491
Validation loss decreased (0.059783 --&gt; 0.054657).  Saving model ...
Epoch: 6/100 	Training Loss: 0.040132 	Validation Loss: 0.301004
Epoch: 7/100 	Training Loss: 0.064483 	Validation Loss: 0.520460
Epoch: 8/100 	Training Loss: 0.206702 	Validation Loss: 0.754766
Validation loss decreased (0.054657 --&gt; 0.049400).  Saving model ...
Epoch: 9/100 	Training Loss: 0.183527 	Validation Loss: 0.366511
Epoch: 10/100 	Training Loss: 0.093996 	Validation Loss: 0.514774
Validation loss decreased (0.049400 --&gt; 0.027266).  Saving model ...
Epoch: 11/100 	Training Loss: 0.104189 	Validation Loss: 0.314198
Epoch: 12/100 	Training Loss: 0.081672 	Validation Loss: 0.398357
Epoch: 13/100 	Training Loss: 0.040366 	Validation Loss: 0.330551
Epoch: 14/100 	Training Loss: 0.079486 	Validation Loss: 0.382618
Epoch: 15/100 	Training Loss: 0.115294 	Validation Loss: 0.516877
Epoch: 16/100 	Training Loss: 0.082678 	Validation Loss: 0.434389
Epoch: 17/100 	Training Loss: 0.066920 	Validation Loss: 0.331327
Validation loss decreased (0.027266 --&gt; 0.025614).  Saving model ...
Epoch: 18/100 	Training Loss: 0.059073 	Validation Loss: 0.360974
Validation loss decreased (0.025614 --&gt; 0.011688).  Saving model ...
Epoch: 19/100 	Training Loss: 0.081646 	Validation Loss: 0.467254
Epoch: 20/100 	Training Loss: 0.069678 	Validation Loss: 0.408296
Epoch: 21/100 	Training Loss: 0.084542 	Validation Loss: 0.386223
Epoch: 22/100 	Training Loss: 0.070551 	Validation Loss: 0.414922
Epoch: 23/100 	Training Loss: 0.045744 	Validation Loss: 0.395099
Epoch: 24/100 	Training Loss: 0.063818 	Validation Loss: 0.400308
Epoch: 25/100 	Training Loss: 0.057635 	Validation Loss: 0.457408
Epoch: 26/100 	Training Loss: 0.076672 	Validation Loss: 0.517089
Epoch: 27/100 	Training Loss: 0.073065 	Validation Loss: 0.441098
Epoch: 28/100 	Training Loss: 0.053564 	Validation Loss: 0.364931
Epoch: 29/100 	Training Loss: 0.048572 	Validation Loss: 0.415386
Epoch: 30/100 	Training Loss: 0.073827 	Validation Loss: 0.597726
Epoch: 31/100 	Training Loss: 0.243700 	Validation Loss: 0.957888
Epoch: 32/100 	Training Loss: 0.231659 	Validation Loss: 0.590247
Epoch: 33/100 	Training Loss: 0.149831 	Validation Loss: 0.459579
Epoch: 34/100 	Training Loss: 0.118337 	Validation Loss: 0.436963
Epoch: 35/100 	Training Loss: 0.046282 	Validation Loss: 0.372253
Epoch: 36/100 	Training Loss: 0.051078 	Validation Loss: 0.445649
Epoch: 37/100 	Training Loss: 0.025400 	Validation Loss: 0.477491
Epoch: 38/100 	Training Loss: 0.049662 	Validation Loss: 0.397876
Epoch: 39/100 	Training Loss: 0.036348 	Validation Loss: 0.469375
Epoch: 40/100 	Training Loss: 0.111113 	Validation Loss: 0.509508
Epoch: 41/100 	Training Loss: 0.118518 	Validation Loss: 0.418067
Epoch: 42/100 	Training Loss: 0.062846 	Validation Loss: 0.450904
Epoch: 43/100 	Training Loss: 0.089022 	Validation Loss: 0.474865
Epoch: 44/100 	Training Loss: 0.114845 	Validation Loss: 0.431467
Validation loss decreased (0.011688 --&gt; 0.010927).  Saving model ...
Epoch: 45/100 	Training Loss: 0.060801 	Validation Loss: 0.464494
Epoch: 46/100 	Training Loss: 0.050133 	Validation Loss: 0.729493
Epoch: 47/100 	Training Loss: 0.070087 	Validation Loss: 0.385108
Epoch: 48/100 	Training Loss: 0.065885 	Validation Loss: 0.474076
Epoch: 49/100 	Training Loss: 0.069880 	Validation Loss: 0.593271
Validation loss decreased (0.010927 --&gt; 0.006609).  Saving model ...
Epoch: 50/100 	Training Loss: 0.123575 	Validation Loss: 0.524230
Epoch: 51/100 	Training Loss: 0.036828 	Validation Loss: 0.487852
Epoch: 52/100 	Training Loss: 0.054506 	Validation Loss: 0.329335
Epoch: 53/100 	Training Loss: 0.014708 	Validation Loss: 0.353836
Validation loss decreased (0.006609 --&gt; 0.001666).  Saving model ...
Epoch: 54/100 	Training Loss: 0.011068 	Validation Loss: 0.349011
Epoch: 55/100 	Training Loss: 0.009514 	Validation Loss: 0.402389
Epoch: 56/100 	Training Loss: 0.044658 	Validation Loss: 0.418317
Epoch: 57/100 	Training Loss: 0.088792 	Validation Loss: 0.408849
Epoch: 58/100 	Training Loss: 0.105863 	Validation Loss: 0.502438
Epoch: 59/100 	Training Loss: 0.263932 	Validation Loss: 1.013313
Epoch: 60/100 	Training Loss: 0.241217 	Validation Loss: 0.612775
Epoch: 61/100 	Training Loss: 0.167609 	Validation Loss: 0.683722
Epoch: 62/100 	Training Loss: 0.200822 	Validation Loss: 0.608539
Epoch: 63/100 	Training Loss: 0.171152 	Validation Loss: 0.576167
Epoch: 64/100 	Training Loss: 0.156759 	Validation Loss: 0.494707
Epoch: 65/100 	Training Loss: 0.192270 	Validation Loss: 0.439826
Epoch: 66/100 	Training Loss: 0.139909 	Validation Loss: 0.364196
Epoch: 67/100 	Training Loss: 0.094022 	Validation Loss: 0.468929
Epoch: 68/100 	Training Loss: 0.119637 	Validation Loss: 0.387247
Epoch: 69/100 	Training Loss: 0.081318 	Validation Loss: 0.367149
Epoch: 70/100 	Training Loss: 0.106263 	Validation Loss: 0.416339
Epoch: 71/100 	Training Loss: 0.049242 	Validation Loss: 0.304694
Epoch: 72/100 	Training Loss: 0.083911 	Validation Loss: 0.329521
Epoch: 73/100 	Training Loss: 0.088274 	Validation Loss: 0.331419
Epoch: 74/100 	Training Loss: 0.053821 	Validation Loss: 0.422738
Epoch: 75/100 	Training Loss: 0.033568 	Validation Loss: 0.372182
Epoch: 76/100 	Training Loss: 0.047355 	Validation Loss: 0.332782
Epoch: 77/100 	Training Loss: 0.077563 	Validation Loss: 0.354360
Epoch: 78/100 	Training Loss: 0.076215 	Validation Loss: 0.526737
Epoch: 79/100 	Training Loss: 0.067217 	Validation Loss: 0.352197
Epoch: 80/100 	Training Loss: 0.086833 	Validation Loss: 0.404810
Epoch: 81/100 	Training Loss: 0.035823 	Validation Loss: 0.348010
Epoch: 82/100 	Training Loss: 0.046359 	Validation Loss: 0.361569
Epoch: 83/100 	Training Loss: 0.066703 	Validation Loss: 0.392023
Epoch: 84/100 	Training Loss: 0.034345 	Validation Loss: 0.344809
Epoch: 85/100 	Training Loss: 0.030991 	Validation Loss: 0.375377
Epoch: 86/100 	Training Loss: 0.038371 	Validation Loss: 0.328979
Epoch: 87/100 	Training Loss: 0.074507 	Validation Loss: 0.394367
Epoch: 88/100 	Training Loss: 0.078844 	Validation Loss: 0.404857
Epoch: 89/100 	Training Loss: 0.047564 	Validation Loss: 0.464238
Epoch: 90/100 	Training Loss: 0.040417 	Validation Loss: 0.422207
Epoch: 91/100 	Training Loss: 0.042731 	Validation Loss: 0.443824
Epoch: 92/100 	Training Loss: 0.078990 	Validation Loss: 0.379293
Epoch: 93/100 	Training Loss: 0.056208 	Validation Loss: 0.317900
Epoch: 94/100 	Training Loss: 0.048740 	Validation Loss: 0.319200
Epoch: 95/100 	Training Loss: 0.019980 	Validation Loss: 0.283820
Epoch: 96/100 	Training Loss: 0.013593 	Validation Loss: 0.293712
Epoch: 97/100 	Training Loss: 0.035475 	Validation Loss: 0.430038
Epoch: 98/100 	Training Loss: 0.071130 	Validation Loss: 0.480383
Epoch: 99/100 	Training Loss: 0.012248 	Validation Loss: 0.432884
Epoch: 100/100 	Training Loss: 0.030615 	Validation Loss: 0.507687
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">x</span>     <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
<span class="n">xi</span>    <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">epochs</span><span class="o">+</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">)]</span>
<span class="n">xi</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">f</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">f</span><span class="o">.</span><span class="n">set_figwidth</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">f</span><span class="o">.</span><span class="n">set_figheight</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">train_losses</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">valid_losses</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">best_epoch</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">xi</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Epochs&quot;</span><span class="p">,</span><span class="n">fontweight</span><span class="o">=</span><span class="s2">&quot;bold&quot;</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;Black&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;15&#39;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">,</span><span class="n">fontweight</span><span class="o">=</span><span class="s2">&quot;bold&quot;</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;Black&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;15&#39;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Losses (with Multi-Head Attention | No PoE)&quot;</span><span class="p">,</span><span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;Black&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;15&#39;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Training Loss&quot;</span><span class="p">,</span><span class="s2">&quot;Valid Loss&quot;</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;Best Epoch= </span><span class="si">{</span><span class="n">best_epoch</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">])</span>


<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">tr_acc</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">val_acc</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">xi</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Epochs&quot;</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;Black&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;15&#39;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">,</span><span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;Black&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;15&#39;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Accuracies (with Multi-Head Attention | No PoE)&quot;</span><span class="p">,</span><span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;Black&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;15&#39;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Training Accuracy&quot;</span><span class="p">,</span><span class="s2">&quot;Valid Accuracy&quot;</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Transformers_32_0.png" src="_images/Transformers_32_0.png" />
</div>
</div>
</section>
<section id="single-head-attention">
<h3>Single-Head Attention<a class="headerlink" href="#single-head-attention" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_head</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">model</span>  <span class="o">=</span> <span class="n">Transformer_Model</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">feed_fwd</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span><span class="n">n_head</span><span class="p">,</span> <span class="n">drop_prob</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">model</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Transformer_Model(
  (layers): ModuleList(
    (0): TransformerBlock(
      (attention): MultiHeadAttention(
        (attention): Attention(
          (softmax): Softmax(dim=-1)
        )
        (w_q): Linear(in_features=300, out_features=300, bias=True)
        (w_k): Linear(in_features=300, out_features=300, bias=True)
        (w_v): Linear(in_features=300, out_features=300, bias=True)
        (w_concat): Linear(in_features=300, out_features=300, bias=True)
      )
      (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)
      (feed_fwd): FeedForward(
        (l1): Linear(in_features=300, out_features=150, bias=True)
        (l2): Linear(in_features=150, out_features=300, bias=True)
        (dropout): Dropout(p=0.0006, inplace=False)
        (relu): ReLU()
      )
      (dropout1): Dropout(p=0.0006, inplace=False)
      (dropout2): Dropout(p=0.0006, inplace=False)
    )
    (1): TransformerBlock(
      (attention): MultiHeadAttention(
        (attention): Attention(
          (softmax): Softmax(dim=-1)
        )
        (w_q): Linear(in_features=300, out_features=300, bias=True)
        (w_k): Linear(in_features=300, out_features=300, bias=True)
        (w_v): Linear(in_features=300, out_features=300, bias=True)
        (w_concat): Linear(in_features=300, out_features=300, bias=True)
      )
      (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)
      (feed_fwd): FeedForward(
        (l1): Linear(in_features=300, out_features=150, bias=True)
        (l2): Linear(in_features=150, out_features=300, bias=True)
        (dropout): Dropout(p=0.0006, inplace=False)
        (relu): ReLU()
      )
      (dropout1): Dropout(p=0.0006, inplace=False)
      (dropout2): Dropout(p=0.0006, inplace=False)
    )
  )
  (linear_out): Linear(in_features=300, out_features=15, bias=True)
)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_losses</span><span class="p">,</span><span class="n">valid_losses</span><span class="p">,</span><span class="n">tr_acc</span><span class="p">,</span><span class="n">val_acc</span><span class="p">,</span><span class="n">best_epoch</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span><span class="n">train_loader</span><span class="p">,</span><span class="n">model</span><span class="p">,</span><span class="n">valid_loader</span><span class="p">,</span><span class="n">optimizer</span><span class="p">,</span><span class="n">criterion</span><span class="p">,</span><span class="n">att_name</span> <span class="o">=</span> <span class="s2">&quot;Single_Att&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Validation loss decreased (inf --&gt; 0.670274).  Saving model ...
Validation loss decreased (0.670274 --&gt; 0.665945).  Saving model ...
Validation loss decreased (0.665945 --&gt; 0.443051).  Saving model ...
Validation loss decreased (0.443051 --&gt; 0.379808).  Saving model ...
Validation loss decreased (0.379808 --&gt; 0.362187).  Saving model ...
Epoch: 1/100 	Training Loss: 1.203470 	Validation Loss: 0.659406
Validation loss decreased (0.362187 --&gt; 0.281843).  Saving model ...
Validation loss decreased (0.281843 --&gt; 0.245898).  Saving model ...
Epoch: 2/100 	Training Loss: 0.369324 	Validation Loss: 0.539507
Validation loss decreased (0.245898 --&gt; 0.173824).  Saving model ...
Epoch: 3/100 	Training Loss: 0.210527 	Validation Loss: 0.426767
Validation loss decreased (0.173824 --&gt; 0.161354).  Saving model ...
Validation loss decreased (0.161354 --&gt; 0.034325).  Saving model ...
Epoch: 4/100 	Training Loss: 0.100236 	Validation Loss: 0.315957
Epoch: 5/100 	Training Loss: 0.066513 	Validation Loss: 0.348473
Epoch: 6/100 	Training Loss: 0.052239 	Validation Loss: 0.435127
Epoch: 7/100 	Training Loss: 0.087608 	Validation Loss: 0.659768
Epoch: 8/100 	Training Loss: 0.194761 	Validation Loss: 0.476744
Epoch: 9/100 	Training Loss: 0.134469 	Validation Loss: 0.386569
Validation loss decreased (0.034325 --&gt; 0.030167).  Saving model ...
Epoch: 10/100 	Training Loss: 0.155075 	Validation Loss: 0.418760
Epoch: 11/100 	Training Loss: 0.103417 	Validation Loss: 0.415741
Epoch: 12/100 	Training Loss: 0.168599 	Validation Loss: 0.549470
Validation loss decreased (0.030167 --&gt; 0.028360).  Saving model ...
Epoch: 13/100 	Training Loss: 0.096715 	Validation Loss: 0.357072
Epoch: 14/100 	Training Loss: 0.030399 	Validation Loss: 0.381699
Validation loss decreased (0.028360 --&gt; 0.018037).  Saving model ...
Epoch: 15/100 	Training Loss: 0.031881 	Validation Loss: 0.422979
Epoch: 16/100 	Training Loss: 0.055526 	Validation Loss: 0.361260
Epoch: 17/100 	Training Loss: 0.057037 	Validation Loss: 0.436855
Epoch: 18/100 	Training Loss: 0.064654 	Validation Loss: 0.576897
Epoch: 19/100 	Training Loss: 0.053953 	Validation Loss: 0.423434
Epoch: 20/100 	Training Loss: 0.056646 	Validation Loss: 0.448038
Epoch: 21/100 	Training Loss: 0.092678 	Validation Loss: 0.522650
Epoch: 22/100 	Training Loss: 0.128115 	Validation Loss: 0.489925
Epoch: 23/100 	Training Loss: 0.090010 	Validation Loss: 0.515487
Epoch: 24/100 	Training Loss: 0.080340 	Validation Loss: 0.365885
Validation loss decreased (0.018037 --&gt; 0.010322).  Saving model ...
Epoch: 25/100 	Training Loss: 0.035688 	Validation Loss: 0.316126
Epoch: 26/100 	Training Loss: 0.030792 	Validation Loss: 0.394303
Epoch: 27/100 	Training Loss: 0.040133 	Validation Loss: 0.386684
Epoch: 28/100 	Training Loss: 0.073460 	Validation Loss: 0.577634
Epoch: 29/100 	Training Loss: 0.101468 	Validation Loss: 0.505033
Epoch: 30/100 	Training Loss: 0.071298 	Validation Loss: 0.557507
Epoch: 31/100 	Training Loss: 0.094200 	Validation Loss: 0.473486
Epoch: 32/100 	Training Loss: 0.043671 	Validation Loss: 0.479440
Epoch: 33/100 	Training Loss: 0.152312 	Validation Loss: 0.542987
Epoch: 34/100 	Training Loss: 0.074871 	Validation Loss: 0.588983
Epoch: 35/100 	Training Loss: 0.090009 	Validation Loss: 0.523235
Epoch: 36/100 	Training Loss: 0.109117 	Validation Loss: 0.410321
Epoch: 37/100 	Training Loss: 0.149858 	Validation Loss: 0.655263
Epoch: 38/100 	Training Loss: 0.082310 	Validation Loss: 0.394052
Epoch: 39/100 	Training Loss: 0.161748 	Validation Loss: 0.578160
Epoch: 40/100 	Training Loss: 0.133597 	Validation Loss: 0.440237
Epoch: 41/100 	Training Loss: 0.082854 	Validation Loss: 0.373093
Epoch: 42/100 	Training Loss: 0.042137 	Validation Loss: 0.503642
Epoch: 43/100 	Training Loss: 0.030415 	Validation Loss: 0.347608
Epoch: 44/100 	Training Loss: 0.046887 	Validation Loss: 0.455899
Epoch: 45/100 	Training Loss: 0.069083 	Validation Loss: 0.626795
Epoch: 46/100 	Training Loss: 0.092766 	Validation Loss: 0.489745
Epoch: 47/100 	Training Loss: 0.058148 	Validation Loss: 0.402053
Epoch: 48/100 	Training Loss: 0.082410 	Validation Loss: 0.473448
Epoch: 49/100 	Training Loss: 0.102020 	Validation Loss: 0.528774
Epoch: 50/100 	Training Loss: 0.034138 	Validation Loss: 0.444843
Epoch: 51/100 	Training Loss: 0.033991 	Validation Loss: 0.459327
Epoch: 52/100 	Training Loss: 0.014867 	Validation Loss: 0.500463
Validation loss decreased (0.010322 --&gt; 0.000372).  Saving model ...
Epoch: 53/100 	Training Loss: 0.020671 	Validation Loss: 0.411562
Epoch: 54/100 	Training Loss: 0.017129 	Validation Loss: 0.363910
Epoch: 55/100 	Training Loss: 0.043737 	Validation Loss: 0.537790
Epoch: 56/100 	Training Loss: 0.106369 	Validation Loss: 0.479709
Epoch: 57/100 	Training Loss: 0.109186 	Validation Loss: 0.545322
Epoch: 58/100 	Training Loss: 0.146838 	Validation Loss: 0.433284
Epoch: 59/100 	Training Loss: 0.059113 	Validation Loss: 0.487111
Epoch: 60/100 	Training Loss: 0.048511 	Validation Loss: 0.359710
Epoch: 61/100 	Training Loss: 0.044794 	Validation Loss: 0.456151
Epoch: 62/100 	Training Loss: 0.077193 	Validation Loss: 0.374097
Epoch: 63/100 	Training Loss: 0.065457 	Validation Loss: 0.619239
Epoch: 64/100 	Training Loss: 0.086623 	Validation Loss: 0.483921
Epoch: 65/100 	Training Loss: 0.066416 	Validation Loss: 0.420639
Epoch: 66/100 	Training Loss: 0.100209 	Validation Loss: 0.450672
Epoch: 67/100 	Training Loss: 0.049652 	Validation Loss: 0.380661
Epoch: 68/100 	Training Loss: 0.055746 	Validation Loss: 0.421704
Epoch: 69/100 	Training Loss: 0.059486 	Validation Loss: 0.728084
Epoch: 70/100 	Training Loss: 0.104905 	Validation Loss: 0.542730
Epoch: 71/100 	Training Loss: 0.075173 	Validation Loss: 0.578584
Epoch: 72/100 	Training Loss: 0.106489 	Validation Loss: 0.462360
Epoch: 73/100 	Training Loss: 0.052133 	Validation Loss: 0.541771
Epoch: 74/100 	Training Loss: 0.057043 	Validation Loss: 0.447700
Epoch: 75/100 	Training Loss: 0.043113 	Validation Loss: 0.376608
Epoch: 76/100 	Training Loss: 0.093532 	Validation Loss: 0.505360
Epoch: 77/100 	Training Loss: 0.151281 	Validation Loss: 0.441348
Epoch: 78/100 	Training Loss: 0.094366 	Validation Loss: 0.413725
Epoch: 79/100 	Training Loss: 0.072633 	Validation Loss: 0.381393
Epoch: 80/100 	Training Loss: 0.052367 	Validation Loss: 0.361087
Epoch: 81/100 	Training Loss: 0.033675 	Validation Loss: 0.348173
Epoch: 82/100 	Training Loss: 0.034196 	Validation Loss: 0.374072
Epoch: 83/100 	Training Loss: 0.033633 	Validation Loss: 0.429886
Epoch: 84/100 	Training Loss: 0.035460 	Validation Loss: 0.388525
Epoch: 85/100 	Training Loss: 0.024090 	Validation Loss: 0.468042
Epoch: 86/100 	Training Loss: 0.034771 	Validation Loss: 0.397996
Epoch: 87/100 	Training Loss: 0.019594 	Validation Loss: 0.398146
Epoch: 88/100 	Training Loss: 0.019682 	Validation Loss: 0.418805
Epoch: 89/100 	Training Loss: 0.029084 	Validation Loss: 0.415976
Epoch: 90/100 	Training Loss: 0.006543 	Validation Loss: 0.339160
Epoch: 91/100 	Training Loss: 0.026241 	Validation Loss: 0.615171
Epoch: 92/100 	Training Loss: 0.065045 	Validation Loss: 0.545524
Epoch: 93/100 	Training Loss: 0.083952 	Validation Loss: 0.450962
Epoch: 94/100 	Training Loss: 0.056833 	Validation Loss: 0.580097
Epoch: 95/100 	Training Loss: 0.083632 	Validation Loss: 0.363249
Epoch: 96/100 	Training Loss: 0.057386 	Validation Loss: 0.362069
Epoch: 97/100 	Training Loss: 0.072339 	Validation Loss: 0.426679
Epoch: 98/100 	Training Loss: 0.068940 	Validation Loss: 0.359773
Epoch: 99/100 	Training Loss: 0.055868 	Validation Loss: 0.445841
Epoch: 100/100 	Training Loss: 0.038962 	Validation Loss: 0.457333
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span>     <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
<span class="n">xi</span>    <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">epochs</span><span class="o">+</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">)]</span>
<span class="n">xi</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">f</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">f</span><span class="o">.</span><span class="n">set_figwidth</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">f</span><span class="o">.</span><span class="n">set_figheight</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">train_losses</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">valid_losses</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">best_epoch</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">xi</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Epochs&quot;</span><span class="p">,</span><span class="n">fontweight</span><span class="o">=</span><span class="s2">&quot;bold&quot;</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;Black&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;15&#39;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">,</span><span class="n">fontweight</span><span class="o">=</span><span class="s2">&quot;bold&quot;</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;Black&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;15&#39;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Losses (with 1-Head Attention | No PoE)&quot;</span><span class="p">,</span><span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;Black&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;15&#39;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Training Loss&quot;</span><span class="p">,</span><span class="s2">&quot;Valid Loss&quot;</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;Best Epoch= </span><span class="si">{</span><span class="n">best_epoch</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">])</span>


<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">tr_acc</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">val_acc</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">xi</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Epochs&quot;</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;Black&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;15&#39;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">,</span><span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;Black&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;15&#39;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Accuracies (with 1-Head Attention | No PoE)&quot;</span><span class="p">,</span><span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;Black&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;15&#39;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Training Accuracy&quot;</span><span class="p">,</span><span class="s2">&quot;Valid Accuracy&quot;</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Transformers_36_0.png" src="_images/Transformers_36_0.png" />
</div>
</div>
</section>
</section>
<section id="testing-no-poe">
<h2>Testing (No PoE)<a class="headerlink" href="#testing-no-poe" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">test_loader</span><span class="p">,</span><span class="n">net</span><span class="p">):</span>
    <span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">num_correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">valid_acc</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
        <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">inputs</span><span class="p">)[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">,:]</span>

        <span class="n">pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span> 
        <span class="n">top_value</span><span class="p">,</span> <span class="n">top_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">correct_tensor</span> <span class="o">=</span> <span class="n">top_index</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">top_index</span><span class="p">))</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">correct_tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
        <span class="n">num_correct</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">)</span>
    
    <span class="n">test_acc</span> <span class="o">=</span> <span class="n">num_correct</span><span class="o">/</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test accuracy: </span><span class="si">{:.3f}</span><span class="s2"> %&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_acc</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<section id="id2">
<h3>Multi-Head Attention<a class="headerlink" href="#id2" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Transformer_Model</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">feed_fwd</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">n_head</span><span class="p">,</span> <span class="n">drop_prob</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;Multi_Att.pt&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;All keys matched successfully&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test</span><span class="p">(</span><span class="n">test_loader</span><span class="p">,</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test accuracy: 95.734 %
</pre></div>
</div>
</div>
</div>
</section>
<section id="id3">
<h3>Single-Head Attention<a class="headerlink" href="#id3" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Transformer_Model</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">feed_fwd</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">n_head</span><span class="p">,</span> <span class="n">drop_prob</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;Single_Att.pt&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;All keys matched successfully&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test</span><span class="p">(</span><span class="n">test_loader</span><span class="p">,</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test accuracy: 95.040 %
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="training-with-poe">
<h2>Training (with PoE)<a class="headerlink" href="#training-with-poe" title="Permalink to this headline">#</a></h2>
<section id="id4">
<h3>Multi-Head Attention<a class="headerlink" href="#id4" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">epochs</span>     <span class="o">=</span> <span class="mi">100</span>
<span class="n">d_model</span>    <span class="o">=</span> <span class="mi">300</span>
<span class="n">feed_fwd</span>   <span class="o">=</span> <span class="mi">150</span>
<span class="n">output_dim</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">n_head</span>     <span class="o">=</span> <span class="mi">4</span>
<span class="n">n_layers</span>   <span class="o">=</span> <span class="mi">2</span>
<span class="n">drop_prob</span>  <span class="o">=</span> <span class="mf">0.0006</span>
<span class="n">lr</span>         <span class="o">=</span> <span class="mf">0.001</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Transformer_Model_PoE</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">feed_fwd</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span><span class="n">n_head</span><span class="p">,</span> <span class="n">drop_prob</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">model</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Transformer_Model_PoE(
  (po_en): PositionalEncoding()
  (layers): ModuleList(
    (0): TransformerBlock(
      (attention): MultiHeadAttention(
        (attention): Attention(
          (softmax): Softmax(dim=-1)
        )
        (w_q): Linear(in_features=300, out_features=300, bias=True)
        (w_k): Linear(in_features=300, out_features=300, bias=True)
        (w_v): Linear(in_features=300, out_features=300, bias=True)
        (w_concat): Linear(in_features=300, out_features=300, bias=True)
      )
      (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)
      (feed_fwd): FeedForward(
        (l1): Linear(in_features=300, out_features=150, bias=True)
        (l2): Linear(in_features=150, out_features=300, bias=True)
        (dropout): Dropout(p=0.0006, inplace=False)
        (relu): ReLU()
      )
      (dropout1): Dropout(p=0.0006, inplace=False)
      (dropout2): Dropout(p=0.0006, inplace=False)
    )
    (1): TransformerBlock(
      (attention): MultiHeadAttention(
        (attention): Attention(
          (softmax): Softmax(dim=-1)
        )
        (w_q): Linear(in_features=300, out_features=300, bias=True)
        (w_k): Linear(in_features=300, out_features=300, bias=True)
        (w_v): Linear(in_features=300, out_features=300, bias=True)
        (w_concat): Linear(in_features=300, out_features=300, bias=True)
      )
      (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)
      (feed_fwd): FeedForward(
        (l1): Linear(in_features=300, out_features=150, bias=True)
        (l2): Linear(in_features=150, out_features=300, bias=True)
        (dropout): Dropout(p=0.0006, inplace=False)
        (relu): ReLU()
      )
      (dropout1): Dropout(p=0.0006, inplace=False)
      (dropout2): Dropout(p=0.0006, inplace=False)
    )
  )
  (linear_out): Linear(in_features=300, out_features=15, bias=True)
)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_losses</span><span class="p">,</span><span class="n">valid_losses</span><span class="p">,</span><span class="n">tr_acc</span><span class="p">,</span><span class="n">val_acc</span><span class="p">,</span><span class="n">best_epoch</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span><span class="n">train_loader</span><span class="p">,</span><span class="n">model</span><span class="p">,</span><span class="n">valid_loader</span><span class="p">,</span><span class="n">optimizer</span><span class="p">,</span><span class="n">criterion</span><span class="p">,</span><span class="n">att_name</span> <span class="o">=</span> <span class="s2">&quot;PoE_Multi_Att&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Validation loss decreased (inf --&gt; 0.224525).  Saving model ...
Validation loss decreased (0.224525 --&gt; 0.145859).  Saving model ...
Epoch: 1/100 	Training Loss: 1.204954 	Validation Loss: 0.322970
Validation loss decreased (0.145859 --&gt; 0.123071).  Saving model ...
Validation loss decreased (0.123071 --&gt; 0.089464).  Saving model ...
Epoch: 2/100 	Training Loss: 0.166121 	Validation Loss: 0.311907
Validation loss decreased (0.089464 --&gt; 0.067128).  Saving model ...
Epoch: 3/100 	Training Loss: 0.056396 	Validation Loss: 0.298933
Epoch: 4/100 	Training Loss: 0.056011 	Validation Loss: 0.257048
Validation loss decreased (0.067128 --&gt; 0.049225).  Saving model ...
Validation loss decreased (0.049225 --&gt; 0.048082).  Saving model ...
Validation loss decreased (0.048082 --&gt; 0.024283).  Saving model ...
Epoch: 5/100 	Training Loss: 0.053802 	Validation Loss: 0.152691
Epoch: 6/100 	Training Loss: 0.024360 	Validation Loss: 0.261943
Epoch: 7/100 	Training Loss: 0.061409 	Validation Loss: 0.297706
Epoch: 8/100 	Training Loss: 0.144426 	Validation Loss: 0.333791
Epoch: 9/100 	Training Loss: 0.143651 	Validation Loss: 0.278037
Epoch: 10/100 	Training Loss: 0.108299 	Validation Loss: 0.385879
Epoch: 11/100 	Training Loss: 0.117076 	Validation Loss: 0.408305
Epoch: 12/100 	Training Loss: 0.136523 	Validation Loss: 0.303982
Epoch: 13/100 	Training Loss: 0.078262 	Validation Loss: 0.240111
Validation loss decreased (0.024283 --&gt; 0.010877).  Saving model ...
Epoch: 14/100 	Training Loss: 0.037992 	Validation Loss: 0.260714
Epoch: 15/100 	Training Loss: 0.036599 	Validation Loss: 0.282348
Validation loss decreased (0.010877 --&gt; 0.006714).  Saving model ...
Epoch: 16/100 	Training Loss: 0.035240 	Validation Loss: 0.246408
Epoch: 17/100 	Training Loss: 0.043786 	Validation Loss: 0.245164
Epoch: 18/100 	Training Loss: 0.035582 	Validation Loss: 0.310643
Epoch: 19/100 	Training Loss: 0.034163 	Validation Loss: 0.265514
Epoch: 20/100 	Training Loss: 0.096687 	Validation Loss: 0.323951
Epoch: 21/100 	Training Loss: 0.076324 	Validation Loss: 0.291760
Epoch: 22/100 	Training Loss: 0.085367 	Validation Loss: 0.416284
Epoch: 23/100 	Training Loss: 0.109254 	Validation Loss: 0.277392
Epoch: 24/100 	Training Loss: 0.087091 	Validation Loss: 0.296783
Epoch: 25/100 	Training Loss: 0.110608 	Validation Loss: 0.342714
Validation loss decreased (0.006714 --&gt; 0.004445).  Saving model ...
Epoch: 26/100 	Training Loss: 0.066241 	Validation Loss: 0.228947
Epoch: 27/100 	Training Loss: 0.079743 	Validation Loss: 0.316877
Epoch: 28/100 	Training Loss: 0.031873 	Validation Loss: 0.282213
Epoch: 29/100 	Training Loss: 0.056118 	Validation Loss: 0.476067
Epoch: 30/100 	Training Loss: 0.088252 	Validation Loss: 0.301447
Epoch: 31/100 	Training Loss: 0.079356 	Validation Loss: 0.507408
Epoch: 32/100 	Training Loss: 0.034598 	Validation Loss: 0.326201
Epoch: 33/100 	Training Loss: 0.049872 	Validation Loss: 0.393460
Validation loss decreased (0.004445 --&gt; 0.003237).  Saving model ...
Epoch: 34/100 	Training Loss: 0.037980 	Validation Loss: 0.241567
Epoch: 35/100 	Training Loss: 0.047164 	Validation Loss: 0.280311
Epoch: 36/100 	Training Loss: 0.047232 	Validation Loss: 0.300808
Epoch: 37/100 	Training Loss: 0.035042 	Validation Loss: 0.259835
Epoch: 38/100 	Training Loss: 0.078475 	Validation Loss: 0.331857
Epoch: 39/100 	Training Loss: 0.060324 	Validation Loss: 0.318709
Epoch: 40/100 	Training Loss: 0.077646 	Validation Loss: 0.274747
Validation loss decreased (0.003237 --&gt; 0.003177).  Saving model ...
Epoch: 41/100 	Training Loss: 0.051432 	Validation Loss: 0.302430
Epoch: 42/100 	Training Loss: 0.065658 	Validation Loss: 0.233768
Epoch: 43/100 	Training Loss: 0.029014 	Validation Loss: 0.277905
Epoch: 44/100 	Training Loss: 0.012493 	Validation Loss: 0.256619
Epoch: 45/100 	Training Loss: 0.029190 	Validation Loss: 0.324238
Epoch: 46/100 	Training Loss: 0.059068 	Validation Loss: 0.371494
Epoch: 47/100 	Training Loss: 0.072548 	Validation Loss: 0.524115
Epoch: 48/100 	Training Loss: 0.115847 	Validation Loss: 0.454417
Validation loss decreased (0.003177 --&gt; 0.002652).  Saving model ...
Epoch: 49/100 	Training Loss: 0.125703 	Validation Loss: 0.340000
Epoch: 50/100 	Training Loss: 0.033770 	Validation Loss: 0.351217
Epoch: 51/100 	Training Loss: 0.068672 	Validation Loss: 0.339708
Epoch: 52/100 	Training Loss: 0.040478 	Validation Loss: 0.305258
Epoch: 53/100 	Training Loss: 0.026259 	Validation Loss: 0.361250
Epoch: 54/100 	Training Loss: 0.013261 	Validation Loss: 0.383301
Epoch: 55/100 	Training Loss: 0.022462 	Validation Loss: 0.352197
Epoch: 56/100 	Training Loss: 0.046061 	Validation Loss: 0.387276
Epoch: 57/100 	Training Loss: 0.050547 	Validation Loss: 0.316371
Epoch: 58/100 	Training Loss: 0.044737 	Validation Loss: 0.403597
Epoch: 59/100 	Training Loss: 0.086299 	Validation Loss: 0.416862
Epoch: 60/100 	Training Loss: 0.076014 	Validation Loss: 0.347792
Epoch: 61/100 	Training Loss: 0.061877 	Validation Loss: 0.479257
Epoch: 62/100 	Training Loss: 0.078754 	Validation Loss: 0.514891
Epoch: 63/100 	Training Loss: 0.116662 	Validation Loss: 0.507343
Epoch: 64/100 	Training Loss: 0.086655 	Validation Loss: 0.369787
Epoch: 65/100 	Training Loss: 0.092974 	Validation Loss: 0.472827
Epoch: 66/100 	Training Loss: 0.072048 	Validation Loss: 0.457369
Epoch: 67/100 	Training Loss: 0.046821 	Validation Loss: 0.420495
Epoch: 68/100 	Training Loss: 0.049584 	Validation Loss: 0.244122
Epoch: 69/100 	Training Loss: 0.045998 	Validation Loss: 0.365603
Epoch: 70/100 	Training Loss: 0.061003 	Validation Loss: 0.292492
Epoch: 71/100 	Training Loss: 0.053457 	Validation Loss: 0.475248
Epoch: 72/100 	Training Loss: 0.059397 	Validation Loss: 0.542692
Epoch: 73/100 	Training Loss: 0.082474 	Validation Loss: 0.277826
Epoch: 74/100 	Training Loss: 0.069366 	Validation Loss: 0.449518
Epoch: 75/100 	Training Loss: 0.107915 	Validation Loss: 0.507135
Epoch: 76/100 	Training Loss: 0.065538 	Validation Loss: 0.422391
Epoch: 77/100 	Training Loss: 0.046049 	Validation Loss: 0.331349
Epoch: 78/100 	Training Loss: 0.052643 	Validation Loss: 0.293502
Epoch: 79/100 	Training Loss: 0.020460 	Validation Loss: 0.298530
Epoch: 80/100 	Training Loss: 0.005298 	Validation Loss: 0.285375
Validation loss decreased (0.002652 --&gt; 0.000237).  Saving model ...
Epoch: 81/100 	Training Loss: 0.004219 	Validation Loss: 0.319867
Epoch: 82/100 	Training Loss: 0.005399 	Validation Loss: 0.296216
Epoch: 83/100 	Training Loss: 0.019674 	Validation Loss: 0.454898
Epoch: 84/100 	Training Loss: 0.049881 	Validation Loss: 0.365309
Epoch: 85/100 	Training Loss: 0.093427 	Validation Loss: 0.499560
Epoch: 86/100 	Training Loss: 0.078942 	Validation Loss: 0.385703
Epoch: 87/100 	Training Loss: 0.070405 	Validation Loss: 0.315985
Epoch: 88/100 	Training Loss: 0.046331 	Validation Loss: 0.417209
Epoch: 89/100 	Training Loss: 0.072109 	Validation Loss: 0.492670
Epoch: 90/100 	Training Loss: 0.082867 	Validation Loss: 0.532978
Epoch: 91/100 	Training Loss: 0.135719 	Validation Loss: 0.457062
Epoch: 92/100 	Training Loss: 0.064654 	Validation Loss: 0.559823
Epoch: 93/100 	Training Loss: 0.080330 	Validation Loss: 0.435790
Epoch: 94/100 	Training Loss: 0.063970 	Validation Loss: 0.358308
Epoch: 95/100 	Training Loss: 0.099889 	Validation Loss: 0.453494
Epoch: 96/100 	Training Loss: 0.169848 	Validation Loss: 0.469199
Epoch: 97/100 	Training Loss: 0.139402 	Validation Loss: 0.499761
Epoch: 98/100 	Training Loss: 0.107400 	Validation Loss: 0.534994
Epoch: 99/100 	Training Loss: 0.092577 	Validation Loss: 0.435534
Epoch: 100/100 	Training Loss: 0.043686 	Validation Loss: 0.521087
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span>     <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
<span class="n">xi</span>    <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">epochs</span><span class="o">+</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">)]</span>
<span class="n">xi</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">f</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">f</span><span class="o">.</span><span class="n">set_figwidth</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">f</span><span class="o">.</span><span class="n">set_figheight</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">train_losses</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">valid_losses</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">best_epoch</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">xi</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Epochs&quot;</span><span class="p">,</span><span class="n">fontweight</span><span class="o">=</span><span class="s2">&quot;bold&quot;</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;Black&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;15&#39;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">,</span><span class="n">fontweight</span><span class="o">=</span><span class="s2">&quot;bold&quot;</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;Black&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;15&#39;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Losses (with Multi-Head Attention | PoE)&quot;</span><span class="p">,</span><span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;Black&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;15&#39;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Training Loss&quot;</span><span class="p">,</span><span class="s2">&quot;Valid Loss&quot;</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;Best Epoch= </span><span class="si">{</span><span class="n">best_epoch</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">])</span>


<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">tr_acc</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">val_acc</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">xi</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Epochs&quot;</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;Black&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;15&#39;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">,</span><span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;Black&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;15&#39;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Accuracies (with Multi-Head Attention | PoE)&quot;</span><span class="p">,</span><span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;Black&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;15&#39;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Training Accuracy&quot;</span><span class="p">,</span><span class="s2">&quot;Valid Accuracy&quot;</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Transformers_50_0.png" src="_images/Transformers_50_0.png" />
</div>
</div>
</section>
<section id="id5">
<h3>Single-Head Attention<a class="headerlink" href="#id5" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_head</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">model</span>  <span class="o">=</span> <span class="n">Transformer_Model_PoE</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">feed_fwd</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span><span class="n">n_head</span><span class="p">,</span> <span class="n">drop_prob</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">model</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Transformer_Model_PoE(
  (po_en): PositionalEncoding()
  (layers): ModuleList(
    (0): TransformerBlock(
      (attention): MultiHeadAttention(
        (attention): Attention(
          (softmax): Softmax(dim=-1)
        )
        (w_q): Linear(in_features=300, out_features=300, bias=True)
        (w_k): Linear(in_features=300, out_features=300, bias=True)
        (w_v): Linear(in_features=300, out_features=300, bias=True)
        (w_concat): Linear(in_features=300, out_features=300, bias=True)
      )
      (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)
      (feed_fwd): FeedForward(
        (l1): Linear(in_features=300, out_features=150, bias=True)
        (l2): Linear(in_features=150, out_features=300, bias=True)
        (dropout): Dropout(p=0.0006, inplace=False)
        (relu): ReLU()
      )
      (dropout1): Dropout(p=0.0006, inplace=False)
      (dropout2): Dropout(p=0.0006, inplace=False)
    )
    (1): TransformerBlock(
      (attention): MultiHeadAttention(
        (attention): Attention(
          (softmax): Softmax(dim=-1)
        )
        (w_q): Linear(in_features=300, out_features=300, bias=True)
        (w_k): Linear(in_features=300, out_features=300, bias=True)
        (w_v): Linear(in_features=300, out_features=300, bias=True)
        (w_concat): Linear(in_features=300, out_features=300, bias=True)
      )
      (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)
      (feed_fwd): FeedForward(
        (l1): Linear(in_features=300, out_features=150, bias=True)
        (l2): Linear(in_features=150, out_features=300, bias=True)
        (dropout): Dropout(p=0.0006, inplace=False)
        (relu): ReLU()
      )
      (dropout1): Dropout(p=0.0006, inplace=False)
      (dropout2): Dropout(p=0.0006, inplace=False)
    )
  )
  (linear_out): Linear(in_features=300, out_features=15, bias=True)
)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_losses</span><span class="p">,</span><span class="n">valid_losses</span><span class="p">,</span><span class="n">tr_acc</span><span class="p">,</span><span class="n">val_acc</span><span class="p">,</span><span class="n">best_epoch</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span><span class="n">train_loader</span><span class="p">,</span><span class="n">model</span><span class="p">,</span><span class="n">valid_loader</span><span class="p">,</span><span class="n">optimizer</span><span class="p">,</span><span class="n">criterion</span><span class="p">,</span><span class="n">att_name</span> <span class="o">=</span> <span class="s2">&quot;PoE_Single_Att&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Validation loss decreased (inf --&gt; 0.821588).  Saving model ...
Validation loss decreased (0.821588 --&gt; 0.557647).  Saving model ...
Validation loss decreased (0.557647 --&gt; 0.532402).  Saving model ...
Validation loss decreased (0.532402 --&gt; 0.511637).  Saving model ...
Validation loss decreased (0.511637 --&gt; 0.496206).  Saving model ...
Validation loss decreased (0.496206 --&gt; 0.335131).  Saving model ...
Validation loss decreased (0.335131 --&gt; 0.314362).  Saving model ...
Epoch: 1/100 	Training Loss: 1.379481 	Validation Loss: 0.586559
Validation loss decreased (0.314362 --&gt; 0.293370).  Saving model ...
Validation loss decreased (0.293370 --&gt; 0.262467).  Saving model ...
Validation loss decreased (0.262467 --&gt; 0.162721).  Saving model ...
Epoch: 2/100 	Training Loss: 0.358122 	Validation Loss: 0.422133
Epoch: 3/100 	Training Loss: 0.197197 	Validation Loss: 0.416594
Validation loss decreased (0.162721 --&gt; 0.078922).  Saving model ...
Epoch: 4/100 	Training Loss: 0.127286 	Validation Loss: 0.305977
Validation loss decreased (0.078922 --&gt; 0.072700).  Saving model ...
Epoch: 5/100 	Training Loss: 0.110021 	Validation Loss: 0.320919
Validation loss decreased (0.072700 --&gt; 0.028288).  Saving model ...
Epoch: 6/100 	Training Loss: 0.101127 	Validation Loss: 0.379341
Epoch: 7/100 	Training Loss: 0.144874 	Validation Loss: 0.383462
Epoch: 8/100 	Training Loss: 0.106468 	Validation Loss: 0.393286
Epoch: 9/100 	Training Loss: 0.130605 	Validation Loss: 0.343040
Validation loss decreased (0.028288 --&gt; 0.023718).  Saving model ...
Epoch: 10/100 	Training Loss: 0.085208 	Validation Loss: 0.371912
Epoch: 11/100 	Training Loss: 0.117072 	Validation Loss: 0.340212
Validation loss decreased (0.023718 --&gt; 0.015954).  Saving model ...
Epoch: 12/100 	Training Loss: 0.097096 	Validation Loss: 0.338026
Epoch: 13/100 	Training Loss: 0.132293 	Validation Loss: 0.473921
Epoch: 14/100 	Training Loss: 0.142122 	Validation Loss: 0.389101
Epoch: 15/100 	Training Loss: 0.108866 	Validation Loss: 0.474856
Epoch: 16/100 	Training Loss: 0.122802 	Validation Loss: 0.370556
Validation loss decreased (0.015954 --&gt; 0.014561).  Saving model ...
Epoch: 17/100 	Training Loss: 0.101154 	Validation Loss: 0.505862
Epoch: 18/100 	Training Loss: 0.108760 	Validation Loss: 0.400512
Epoch: 19/100 	Training Loss: 0.101475 	Validation Loss: 0.492645
Epoch: 20/100 	Training Loss: 0.082388 	Validation Loss: 0.437826
Validation loss decreased (0.014561 --&gt; 0.009814).  Saving model ...
Epoch: 21/100 	Training Loss: 0.087468 	Validation Loss: 0.330588
Epoch: 22/100 	Training Loss: 0.088960 	Validation Loss: 0.385745
Epoch: 23/100 	Training Loss: 0.103565 	Validation Loss: 0.673390
Epoch: 24/100 	Training Loss: 0.137995 	Validation Loss: 0.331254
Epoch: 25/100 	Training Loss: 0.082071 	Validation Loss: 0.397604
Epoch: 26/100 	Training Loss: 0.105750 	Validation Loss: 0.379677
Epoch: 27/100 	Training Loss: 0.096163 	Validation Loss: 0.312470
Epoch: 28/100 	Training Loss: 0.085460 	Validation Loss: 0.450953
Epoch: 29/100 	Training Loss: 0.130514 	Validation Loss: 0.384807
Epoch: 30/100 	Training Loss: 0.077238 	Validation Loss: 0.395485
Epoch: 31/100 	Training Loss: 0.065043 	Validation Loss: 0.485181
Epoch: 32/100 	Training Loss: 0.099660 	Validation Loss: 0.412234
Epoch: 33/100 	Training Loss: 0.075033 	Validation Loss: 0.402974
Epoch: 34/100 	Training Loss: 0.076304 	Validation Loss: 0.556953
Epoch: 35/100 	Training Loss: 0.152852 	Validation Loss: 0.566904
Epoch: 36/100 	Training Loss: 0.247087 	Validation Loss: 0.522874
Epoch: 37/100 	Training Loss: 0.128696 	Validation Loss: 0.444976
Epoch: 38/100 	Training Loss: 0.090852 	Validation Loss: 0.593070
Epoch: 39/100 	Training Loss: 0.110304 	Validation Loss: 0.384037
Epoch: 40/100 	Training Loss: 0.072743 	Validation Loss: 0.418071
Epoch: 41/100 	Training Loss: 0.064179 	Validation Loss: 0.412008
Epoch: 42/100 	Training Loss: 0.058943 	Validation Loss: 0.297038
Epoch: 43/100 	Training Loss: 0.041025 	Validation Loss: 0.368841
Epoch: 44/100 	Training Loss: 0.067036 	Validation Loss: 0.528340
Epoch: 45/100 	Training Loss: 0.121187 	Validation Loss: 0.911075
Epoch: 46/100 	Training Loss: 0.165811 	Validation Loss: 0.668519
Epoch: 47/100 	Training Loss: 0.106671 	Validation Loss: 0.610053
Epoch: 48/100 	Training Loss: 0.108058 	Validation Loss: 0.462727
Epoch: 49/100 	Training Loss: 0.073048 	Validation Loss: 0.556632
Epoch: 50/100 	Training Loss: 0.125498 	Validation Loss: 0.417138
Epoch: 51/100 	Training Loss: 0.071747 	Validation Loss: 0.464448
Epoch: 52/100 	Training Loss: 0.081477 	Validation Loss: 0.425778
Epoch: 53/100 	Training Loss: 0.084659 	Validation Loss: 0.534808
Epoch: 54/100 	Training Loss: 0.065797 	Validation Loss: 0.543350
Epoch: 55/100 	Training Loss: 0.108418 	Validation Loss: 0.458494
Epoch: 56/100 	Training Loss: 0.069357 	Validation Loss: 0.500402
Epoch: 57/100 	Training Loss: 0.091122 	Validation Loss: 0.440414
Epoch: 58/100 	Training Loss: 0.090894 	Validation Loss: 0.707763
Epoch: 59/100 	Training Loss: 0.165914 	Validation Loss: 0.579370
Epoch: 60/100 	Training Loss: 0.085919 	Validation Loss: 0.493787
Epoch: 61/100 	Training Loss: 0.124838 	Validation Loss: 0.760627
Epoch: 62/100 	Training Loss: 0.111855 	Validation Loss: 0.529638
Epoch: 63/100 	Training Loss: 0.073252 	Validation Loss: 0.544571
Epoch: 64/100 	Training Loss: 0.051255 	Validation Loss: 0.549383
Epoch: 65/100 	Training Loss: 0.077433 	Validation Loss: 0.750153
Epoch: 66/100 	Training Loss: 0.120876 	Validation Loss: 0.403848
Epoch: 67/100 	Training Loss: 0.052970 	Validation Loss: 0.484706
Epoch: 68/100 	Training Loss: 0.052394 	Validation Loss: 0.584237
Epoch: 69/100 	Training Loss: 0.070929 	Validation Loss: 0.425044
Epoch: 70/100 	Training Loss: 0.083853 	Validation Loss: 0.459321
Epoch: 71/100 	Training Loss: 0.082114 	Validation Loss: 0.616733
Epoch: 72/100 	Training Loss: 0.122934 	Validation Loss: 0.567997
Epoch: 73/100 	Training Loss: 0.092341 	Validation Loss: 0.432456
Epoch: 74/100 	Training Loss: 0.066160 	Validation Loss: 0.553697
Epoch: 75/100 	Training Loss: 0.036482 	Validation Loss: 0.466829
Epoch: 76/100 	Training Loss: 0.033387 	Validation Loss: 0.520527
Epoch: 77/100 	Training Loss: 0.041742 	Validation Loss: 0.624768
Epoch: 78/100 	Training Loss: 0.042502 	Validation Loss: 0.788324
Epoch: 79/100 	Training Loss: 0.087642 	Validation Loss: 0.599930
Epoch: 80/100 	Training Loss: 0.066165 	Validation Loss: 0.537329
Epoch: 81/100 	Training Loss: 0.083664 	Validation Loss: 0.476066
Epoch: 82/100 	Training Loss: 0.066226 	Validation Loss: 0.488191
Epoch: 83/100 	Training Loss: 0.054058 	Validation Loss: 0.467985
Epoch: 84/100 	Training Loss: 0.066512 	Validation Loss: 0.445913
Epoch: 85/100 	Training Loss: 0.084781 	Validation Loss: 0.524811
Epoch: 86/100 	Training Loss: 0.113819 	Validation Loss: 0.545308
Epoch: 87/100 	Training Loss: 0.061780 	Validation Loss: 0.428236
Epoch: 88/100 	Training Loss: 0.060007 	Validation Loss: 0.501109
Epoch: 89/100 	Training Loss: 0.087123 	Validation Loss: 0.608446
Epoch: 90/100 	Training Loss: 0.135691 	Validation Loss: 0.500220
Epoch: 91/100 	Training Loss: 0.060262 	Validation Loss: 0.428601
Epoch: 92/100 	Training Loss: 0.079480 	Validation Loss: 0.427611
Epoch: 93/100 	Training Loss: 0.071183 	Validation Loss: 0.452061
Epoch: 94/100 	Training Loss: 0.051626 	Validation Loss: 0.646002
Epoch: 95/100 	Training Loss: 0.106435 	Validation Loss: 0.553080
Epoch: 96/100 	Training Loss: 0.063010 	Validation Loss: 0.455809
Epoch: 97/100 	Training Loss: 0.058758 	Validation Loss: 0.515106
Epoch: 98/100 	Training Loss: 0.077400 	Validation Loss: 0.570842
Epoch: 99/100 	Training Loss: 0.067423 	Validation Loss: 0.492861
Epoch: 100/100 	Training Loss: 0.079162 	Validation Loss: 0.668110
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span>     <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
<span class="n">xi</span>    <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">epochs</span><span class="o">+</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">)]</span>
<span class="n">xi</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">f</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">f</span><span class="o">.</span><span class="n">set_figwidth</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">f</span><span class="o">.</span><span class="n">set_figheight</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">train_losses</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">valid_losses</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">best_epoch</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">xi</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Epochs&quot;</span><span class="p">,</span><span class="n">fontweight</span><span class="o">=</span><span class="s2">&quot;bold&quot;</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;Black&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;15&#39;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">,</span><span class="n">fontweight</span><span class="o">=</span><span class="s2">&quot;bold&quot;</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;Black&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;15&#39;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Losses (with 1-Head Attention | PoE)&quot;</span><span class="p">,</span><span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;Black&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;15&#39;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Training Loss&quot;</span><span class="p">,</span><span class="s2">&quot;Valid Loss&quot;</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;Best Epoch= </span><span class="si">{</span><span class="n">best_epoch</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">])</span>


<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">tr_acc</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">val_acc</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">xi</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Epochs&quot;</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;Black&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;15&#39;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">,</span><span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;Black&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;15&#39;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Accuracies (with 1-Head Attention | PoE)&quot;</span><span class="p">,</span><span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;Black&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;15&#39;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Training Accuracy&quot;</span><span class="p">,</span><span class="s2">&quot;Valid Accuracy&quot;</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Transformers_54_0.png" src="_images/Transformers_54_0.png" />
</div>
</div>
</section>
</section>
<section id="testing-with-poe">
<h2>Testing (with PoE)<a class="headerlink" href="#testing-with-poe" title="Permalink to this headline">#</a></h2>
<section id="multi-head">
<h3>Multi-Head<a class="headerlink" href="#multi-head" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Transformer_Model_PoE</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">feed_fwd</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">n_head</span><span class="p">,</span> <span class="n">drop_prob</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;PoE_Multi_Att.pt&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;All keys matched successfully&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test</span><span class="p">(</span><span class="n">test_loader</span><span class="p">,</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test accuracy: 96.875 %
</pre></div>
</div>
</div>
</div>
</section>
<section id="single-head">
<h3>Single-Head<a class="headerlink" href="#single-head" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Transformer_Model_PoE</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">feed_fwd</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">n_head</span><span class="p">,</span> <span class="n">drop_prob</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;PoE_Single_Att.pt&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;All keys matched successfully&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test</span><span class="p">(</span><span class="n">test_loader</span><span class="p">,</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test accuracy: 93.750 %
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="attention_2.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">GRU + Attention</p>
        </div>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Akshat Yadav<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>