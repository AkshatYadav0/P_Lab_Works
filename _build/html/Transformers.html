
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Transformers &#8212; Lab Works</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="GRU + Attention" href="attention_2.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Lab Works</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Home
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="attention_2.html">
   GRU + Attention
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Transformers
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/AkshatYadav0/P_Lab/master?urlpath=tree/Transformers.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/AkshatYadav0/P_Lab"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/AkshatYadav0/P_Lab/issues/new?title=Issue%20on%20page%20%2FTransformers.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/Transformers.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Transformers
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#models">
   MODELS
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#attention">
     Attention
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multi-head-attention">
     Multi Head Attention
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#feed-forward">
     Feed Forward
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complied-model">
     Complied Model
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training">
     Training
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#testing">
     Testing
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Transformers</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Transformers
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#models">
   MODELS
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#attention">
     Attention
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multi-head-attention">
     Multi Head Attention
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#feed-forward">
     Feed Forward
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#complied-model">
     Complied Model
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training">
     Training
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#testing">
     Testing
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="transformers">
<h1>Transformers<a class="headerlink" href="#transformers" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;Data/HCP_movie_watching.pkl&#39;</span><span class="p">,</span><span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">TS</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">TS</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dict_keys([&#39;testretest&#39;, &#39;twomen&#39;, &#39;bridgeville&#39;, &#39;pockets&#39;, &#39;overcome&#39;, &#39;inception&#39;, &#39;socialnet&#39;, &#39;oceans&#39;, &#39;flower&#39;, &#39;hotel&#39;, &#39;garden&#39;, &#39;dreary&#39;, &#39;homealone&#39;, &#39;brokovich&#39;, &#39;starwars&#39;])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rel</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">l</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">movie_name</span><span class="p">,</span> <span class="n">ts</span> <span class="ow">in</span> <span class="n">TS</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">l</span>
    <span class="n">l</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">movie_name</span><span class="p">,</span> <span class="n">ts</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>testretest (4, 176, 84, 300)
twomen (176, 245, 300)
bridgeville (176, 222, 300)
pockets (176, 189, 300)
overcome (176, 65, 300)
inception (176, 227, 300)
socialnet (176, 260, 300)
oceans (176, 250, 300)
flower (176, 181, 300)
hotel (176, 186, 300)
garden (176, 205, 300)
dreary (176, 143, 300)
homealone (176, 233, 300)
brokovich (176, 231, 300)
starwars (176, 256, 300)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_feature</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_feature</span>  <span class="o">=</span> <span class="p">[]</span>
<span class="n">train_target</span>  <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_target</span>   <span class="o">=</span> <span class="p">[]</span>
<span class="n">seq_length</span>    <span class="o">=</span> <span class="mi">198</span>

<span class="k">for</span> <span class="n">movie_name</span><span class="p">,</span> <span class="n">ts</span> <span class="ow">in</span> <span class="n">TS</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">pep</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">movie_name</span> <span class="o">!=</span> <span class="s2">&quot;testretest&quot;</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ts</span><span class="p">:</span>
            <span class="n">pep</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">pep</span> <span class="o">&lt;=</span> <span class="mi">100</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">&gt;</span><span class="n">seq_length</span><span class="p">:</span>
                    <span class="n">k</span> <span class="o">=</span> <span class="n">i</span><span class="p">[:</span><span class="n">seq_length</span><span class="p">][:]</span>
                    <span class="n">train_feature</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
                    <span class="n">train_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">])</span>
                    
                    <span class="n">k</span> <span class="o">=</span> <span class="n">i</span><span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="n">seq_length</span><span class="p">:][:]</span>
                    <span class="n">train_feature</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
                    <span class="n">train_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">])</span>
                
                <span class="k">elif</span> <span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">&lt;</span><span class="n">seq_length</span><span class="p">:</span>
                    <span class="n">k</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">300</span><span class="p">]</span><span class="o">*</span><span class="n">seq_length</span>
                    <span class="n">k</span><span class="p">[</span><span class="n">seq_length</span><span class="o">-</span><span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:]</span> <span class="o">=</span> <span class="n">i</span>
                    <span class="n">train_feature</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
                    <span class="n">train_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">train_feature</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                    <span class="n">train_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">])</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">&gt;</span><span class="n">seq_length</span><span class="p">:</span>
                    <span class="n">k</span> <span class="o">=</span> <span class="n">i</span><span class="p">[:</span><span class="n">seq_length</span><span class="p">][:]</span>
                    <span class="n">test_feature</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
                    <span class="n">test_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">])</span>
                   
                    <span class="n">k</span> <span class="o">=</span> <span class="n">i</span><span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="n">seq_length</span><span class="p">:][:]</span>
                    <span class="n">test_feature</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
                    <span class="n">test_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">])</span>
                
                <span class="k">elif</span> <span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">&lt;</span><span class="n">seq_length</span><span class="p">:</span>
                    <span class="n">k</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">300</span><span class="p">]</span><span class="o">*</span><span class="n">seq_length</span>
                    <span class="n">k</span><span class="p">[</span><span class="n">seq_length</span><span class="o">-</span><span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:]</span> <span class="o">=</span> <span class="n">i</span>
                    <span class="n">test_feature</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
                    <span class="n">test_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">test_feature</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                    <span class="n">test_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">pep</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">jj</span> <span class="ow">in</span> <span class="n">ts</span><span class="p">:</span>
            <span class="n">pep</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">jj</span><span class="p">:</span>
                <span class="n">pep</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">pep</span> <span class="o">&lt;=</span> <span class="mi">101</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">&gt;</span><span class="n">seq_length</span><span class="p">:</span>
                        <span class="n">k</span> <span class="o">=</span> <span class="n">i</span><span class="p">[:</span><span class="n">seq_length</span><span class="p">][:]</span>
                        <span class="n">train_feature</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
                        <span class="n">train_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">])</span>

                        <span class="n">k</span> <span class="o">=</span> <span class="n">i</span><span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="n">seq_length</span><span class="p">:][:]</span>
                        <span class="n">train_feature</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
                        <span class="n">train_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">])</span>

                    <span class="k">elif</span> <span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">&lt;</span><span class="n">seq_length</span><span class="p">:</span>
                        <span class="n">k</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">300</span><span class="p">]</span><span class="o">*</span><span class="n">seq_length</span>
                        <span class="n">k</span><span class="p">[</span><span class="n">seq_length</span><span class="o">-</span><span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:]</span> <span class="o">=</span> <span class="n">i</span>
                        <span class="n">train_feature</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
                        <span class="n">train_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">])</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">train_feature</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                        <span class="n">train_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">])</span>

                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">&gt;</span><span class="n">seq_length</span><span class="p">:</span>
                        <span class="n">k</span> <span class="o">=</span> <span class="n">i</span><span class="p">[:</span><span class="n">seq_length</span><span class="p">][:]</span>
                        <span class="n">test_feature</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
                        <span class="n">test_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">])</span>

                        <span class="n">k</span> <span class="o">=</span> <span class="n">i</span><span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="n">seq_length</span><span class="p">:][:]</span>
                        <span class="n">test_feature</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
                        <span class="n">test_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">])</span>

                    <span class="k">elif</span> <span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">&lt;</span><span class="n">seq_length</span><span class="p">:</span>
                        <span class="n">k</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">300</span><span class="p">]</span><span class="o">*</span><span class="n">seq_length</span>
                        <span class="n">k</span><span class="p">[</span><span class="n">seq_length</span><span class="o">-</span><span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:]</span> <span class="o">=</span> <span class="n">i</span>
                        <span class="n">test_feature</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
                        <span class="n">test_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">])</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">test_feature</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                        <span class="n">test_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rel</span><span class="p">[</span><span class="n">movie_name</span><span class="p">])</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">pep</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>176
176
176
176
176
176
176
176
176
176
176
176
176
176
176
176
176
176
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">TensorDataset</span><span class="p">,</span> <span class="n">DataLoader</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_feature</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_target</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
<span class="n">test_data</span>  <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_feature</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_target</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data.sampler</span> <span class="kn">import</span> <span class="n">SubsetRandomSampler</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">valid_data</span>  <span class="o">=</span> <span class="mf">0.25</span>
<span class="n">t_train</span>     <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
<span class="n">data_no</span>     <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">t_train</span><span class="p">))</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">data_no</span><span class="p">)</span>
<span class="n">split_no</span>    <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">valid_data</span><span class="o">*</span><span class="n">t_train</span><span class="p">))</span>
<span class="n">train</span><span class="p">,</span><span class="n">valid</span> <span class="o">=</span> <span class="n">data_no</span><span class="p">[</span><span class="n">split_no</span><span class="p">:],</span><span class="n">data_no</span><span class="p">[:</span><span class="n">split_no</span><span class="p">]</span>

<span class="n">train_sampler</span> <span class="o">=</span> <span class="n">SubsetRandomSampler</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
<span class="n">valid_sampler</span> <span class="o">=</span> <span class="n">SubsetRandomSampler</span><span class="p">(</span><span class="n">valid</span><span class="p">)</span>

<span class="n">train_loader</span>  <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span><span class="n">sampler</span><span class="o">=</span><span class="n">train_sampler</span><span class="p">,</span><span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">valid_loader</span>  <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span><span class="n">sampler</span><span class="o">=</span><span class="n">valid_sampler</span><span class="p">,</span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span><span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">test_loader</span>   <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span><span class="n">shuffle</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">is_cuda</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>

<span class="k">if</span> <span class="n">is_cuda</span><span class="p">:</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">device</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>device(type=&#39;cuda&#39;)
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="models">
<h1>MODELS<a class="headerlink" href="#models" title="Permalink to this headline">#</a></h1>
<section id="attention">
<h2>Attention<a class="headerlink" href="#attention" title="Permalink to this headline">#</a></h2>
<img alt="_images/scale_dot_product_attention.jpg" src="_images/scale_dot_product_attention.jpg" />
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Attention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    q : current sequence</span>
<span class="sd">    k : every sequence to check relationship with Qeury</span>
<span class="sd">    v : every seq same with Key</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Attention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span> <span class="c1">#, mask=None, e=1e-12):</span>
        <span class="c1"># [batch_size, head, length, d_tensor]</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">head</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">d_tensor</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>

        <span class="c1"># 1. dot product Query with Key^T to compute similarity</span>
        <span class="n">k_t</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="p">(</span><span class="n">q</span> <span class="o">@</span> <span class="n">k_t</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">d_tensor</span><span class="p">)</span>  <span class="c1"># scaled dot product</span>

        <span class="c1"># 2. apply masking (opt)</span>
        <span class="c1">#if mask is not None:</span>
        <span class="c1">#    score = score.masked_fill(mask == 0, -e)</span>

        <span class="c1"># 3. pass them softmax to make [0, 1] range</span>
        <span class="n">score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>

        <span class="c1"># 4. multiply with Value</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">score</span> <span class="o">@</span> <span class="n">v</span>

        <span class="k">return</span> <span class="n">v</span><span class="p">,</span> <span class="n">score</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="multi-head-attention">
<h2>Multi Head Attention<a class="headerlink" href="#multi-head-attention" title="Permalink to this headline">#</a></h2>
<img alt="_images/multi_head_attention.jpg" src="_images/multi_head_attention.jpg" />
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MultiHeadAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">n_head</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MultiHeadAttention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_head</span> <span class="o">=</span> <span class="n">n_head</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">Attention</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w_q</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w_k</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w_v</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w_concat</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        
        <span class="c1"># 1. dot product with weight matrices</span>
        <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_q</span><span class="p">(</span><span class="n">q</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_k</span><span class="p">(</span><span class="n">k</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_v</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

        <span class="c1"># 2. split tensor by number of heads</span>
        <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">q</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">k</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

        <span class="c1"># 3. do scale dot product to compute similarity</span>
        <span class="n">out</span><span class="p">,</span> <span class="n">attention</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span><span class="c1">#, mask=mask)</span>
        
        <span class="c1"># 4. concat and pass to linear layer</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_concat</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="c1"># 5. visualize attention map</span>
        <span class="c1"># TODO : we should implement visualization</span>
        
        <span class="k">return</span> <span class="n">out</span>

    <span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        split tensor by number of head</span>

<span class="sd">        :param tensor: [batch_size, length, d_model]</span>
<span class="sd">        :return: [batch_size, head, length, d_tensor]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">d_model</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>

        <span class="n">d_tensor</span> <span class="o">=</span> <span class="n">d_model</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_head</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_head</span><span class="p">,</span> <span class="n">d_tensor</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="c1"># it is similar with group convolution (split by number of heads)</span>

        <span class="k">return</span> <span class="n">tensor</span>

    <span class="k">def</span> <span class="nf">concat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param tensor: [batch_size, head, length, d_tensor]</span>
<span class="sd">        :return: [batch_size, length, d_model]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">head</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">d_tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
        <span class="n">d_model</span> <span class="o">=</span> <span class="n">head</span> <span class="o">*</span> <span class="n">d_tensor</span>

        <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensor</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="feed-forward">
<h2>Feed Forward<a class="headerlink" href="#feed-forward" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">FeedForward</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span> 
        
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="complied-model">
<h2>Complied Model<a class="headerlink" href="#complied-model" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Transformer_Model</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span><span class="n">n_head</span><span class="p">,</span> <span class="n">drop_prob</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Transformer_Model</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_head</span><span class="o">=</span><span class="n">n_head</span><span class="p">)</span>
        
        <span class="c1">#self.norm1 = LayerNorm(d_model=d_model)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">drop_prob</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">feed_fwd</span> <span class="o">=</span> <span class="n">FeedForward</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">drop_prob</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span> <span class="c1">#LayerNorm(d_model=d_model)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">drop_prob</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span><span class="n">out_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">func</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># 1. compute self attention</span>
        <span class="n">_x</span> <span class="o">=</span> <span class="n">x</span>
        <span class="c1">#print(x.shape)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
        
        <span class="c1"># 2. add and norm</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">_x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="c1"># 3. feed forward network</span>
        <span class="n">_x</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feed_fwd</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
      
        <span class="c1"># 4. add and norm</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">_x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="c1"># 5. Output</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">func</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear_out</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="training">
<h2>Training<a class="headerlink" href="#training" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span><span class="n">train_loader</span><span class="p">,</span><span class="n">net</span><span class="p">,</span><span class="n">valid_loader</span><span class="p">,</span><span class="n">optimzer</span><span class="p">,</span><span class="n">criterion</span><span class="p">,</span><span class="n">att</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">val_acc</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">tr_acc</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="n">clip</span> <span class="o">=</span> <span class="mi">3</span> <span class="c1"># gradient clipping</span>

    <span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    
    <span class="n">valid_loss_min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">Inf</span> 
    
    <span class="n">valid_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">train_losses</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">num_correct</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">train_loss</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">valid_loss</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">train_acc</span>  <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">valid_acc</span>  <span class="o">=</span> <span class="mf">0.0</span> 
        <span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
            
            <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">net</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">inputs</span><span class="p">)[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
            <span class="c1">#print(output[:, -1, :].shape)</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span> 
            
            <span class="n">top_value</span><span class="p">,</span> <span class="n">top_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
            
            <span class="n">correct_tensor</span> <span class="o">=</span> <span class="n">top_index</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">top_index</span><span class="p">))</span>
            <span class="n">correct</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">correct_tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            <span class="n">num_correct</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">)</span>


            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">clip</span><span class="p">)</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">train_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">tr_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">num_correct</span><span class="o">/</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">batch_size</span><span class="p">))</span>

        <span class="n">acc</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">val_losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">num_correct</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">v_c</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">valid_loader</span><span class="p">:</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="n">output</span><span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">inputs</span><span class="p">)[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
            
            <span class="n">pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span> 
            <span class="n">top_value</span><span class="p">,</span> <span class="n">top_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">correct_tensor</span> <span class="o">=</span> <span class="n">top_index</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">top_index</span><span class="p">))</span>
            <span class="n">correct</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">correct_tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            <span class="n">num_correct</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">)</span>

            <span class="n">val_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span><span class="n">labels</span><span class="p">)</span>
            <span class="n">val_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            
            <span class="k">if</span> <span class="n">val_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">valid_loss_min</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation loss decreased (</span><span class="si">{:.6f}</span><span class="s1"> --&gt; </span><span class="si">{:.6f}</span><span class="s1">).  Saving model ...&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">valid_loss_min</span><span class="p">,</span> <span class="n">val_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>
                <span class="n">best_epoch</span> <span class="o">=</span> <span class="n">e</span>
                <span class="k">if</span> <span class="n">att</span><span class="p">:</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;Trns_Multi_Att.pt&#39;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;Trns_Att.pt&#39;</span><span class="p">)</span>
                <span class="n">valid_loss_min</span> <span class="o">=</span> <span class="n">val_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="n">net</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">valid_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">val_losses</span><span class="p">))</span>
        <span class="n">train_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_loss</span><span class="p">))</span>
        <span class="n">val_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">num_correct</span><span class="o">/</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">valid_loader</span><span class="p">)</span><span class="o">*</span><span class="n">batch_size</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch: </span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1"> </span><span class="se">\t</span><span class="s1">Training Loss: </span><span class="si">{:.6f}</span><span class="s1"> </span><span class="se">\t</span><span class="s1">Validation Loss: </span><span class="si">{:.6f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">e</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">epochs</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_loss</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">val_losses</span><span class="p">)))</span>
    
    <span class="k">return</span> <span class="n">train_losses</span><span class="p">,</span><span class="n">valid_losses</span><span class="p">,</span><span class="n">tr_acc</span><span class="p">,</span><span class="n">val_acc</span><span class="p">,</span><span class="n">best_epoch</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">epochs</span>     <span class="o">=</span> <span class="mi">100</span>
<span class="n">d_model</span>    <span class="o">=</span> <span class="mi">300</span>
<span class="n">feed_fwd</span>   <span class="o">=</span> <span class="mi">300</span>
<span class="n">output_dim</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">n_head</span>     <span class="o">=</span> <span class="mi">4</span>
<span class="n">drop_prob</span>  <span class="o">=</span> <span class="mf">0.0006</span>
<span class="n">lr</span>         <span class="o">=</span> <span class="mf">0.001</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Transformer_Model</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">feed_fwd</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span><span class="n">n_head</span><span class="p">,</span> <span class="n">drop_prob</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">model</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Transformer_Model(
  (attention): MultiHeadAttention(
    (attention): Attention(
      (softmax): Softmax(dim=-1)
    )
    (w_q): Linear(in_features=300, out_features=300, bias=True)
    (w_k): Linear(in_features=300, out_features=300, bias=True)
    (w_v): Linear(in_features=300, out_features=300, bias=True)
    (w_concat): Linear(in_features=300, out_features=300, bias=True)
  )
  (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)
  (dropout1): Dropout(p=0.0006, inplace=False)
  (feed_fwd): FeedForward(
    (l1): Linear(in_features=300, out_features=300, bias=True)
    (l2): Linear(in_features=300, out_features=300, bias=True)
    (dropout): Dropout(p=0.0006, inplace=False)
    (relu): ReLU()
  )
  (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)
  (dropout2): Dropout(p=0.0006, inplace=False)
  (linear_out): Linear(in_features=300, out_features=15, bias=True)
  (func): Softmax(dim=-1)
)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_losses</span><span class="p">,</span><span class="n">valid_losses</span><span class="p">,</span><span class="n">tr_acc</span><span class="p">,</span><span class="n">val_acc</span><span class="p">,</span><span class="n">best_epoch</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span><span class="n">train_loader</span><span class="p">,</span><span class="n">model</span><span class="p">,</span><span class="n">valid_loader</span><span class="p">,</span><span class="n">optimizer</span><span class="p">,</span><span class="n">criterion</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Validation loss decreased (inf --&gt; 2.369197).  Saving model ...
Validation loss decreased (2.369197 --&gt; 2.287691).  Saving model ...
Validation loss decreased (2.287691 --&gt; 2.242522).  Saving model ...
Validation loss decreased (2.242522 --&gt; 2.219682).  Saving model ...
Validation loss decreased (2.219682 --&gt; 2.195934).  Saving model ...
Epoch: 1/100 	Training Loss: 2.496149 	Validation Loss: 2.368553
Validation loss decreased (2.195934 --&gt; 2.126452).  Saving model ...
Validation loss decreased (2.126452 --&gt; 2.126295).  Saving model ...
Validation loss decreased (2.126295 --&gt; 2.125395).  Saving model ...
Validation loss decreased (2.125395 --&gt; 2.108857).  Saving model ...
Epoch: 2/100 	Training Loss: 2.245956 	Validation Loss: 2.207429
Validation loss decreased (2.108857 --&gt; 2.011914).  Saving model ...
Epoch: 3/100 	Training Loss: 2.105917 	Validation Loss: 2.141412
Validation loss decreased (2.011914 --&gt; 1.989511).  Saving model ...
Epoch: 4/100 	Training Loss: 2.026542 	Validation Loss: 2.092522
Validation loss decreased (1.989511 --&gt; 1.967464).  Saving model ...
Epoch: 5/100 	Training Loss: 1.988565 	Validation Loss: 2.111349
Validation loss decreased (1.967464 --&gt; 1.953470).  Saving model ...
Validation loss decreased (1.953470 --&gt; 1.950491).  Saving model ...
Validation loss decreased (1.950491 --&gt; 1.943271).  Saving model ...
Epoch: 6/100 	Training Loss: 1.944625 	Validation Loss: 2.052028
Validation loss decreased (1.943271 --&gt; 1.930834).  Saving model ...
Epoch: 7/100 	Training Loss: 1.924850 	Validation Loss: 2.045434
Epoch: 8/100 	Training Loss: 1.910712 	Validation Loss: 2.038442
Validation loss decreased (1.930834 --&gt; 1.914460).  Saving model ...
Epoch: 9/100 	Training Loss: 1.907772 	Validation Loss: 2.024285
Epoch: 10/100 	Training Loss: 1.895903 	Validation Loss: 2.067150
Validation loss decreased (1.914460 --&gt; 1.914453).  Saving model ...
Epoch: 11/100 	Training Loss: 1.897827 	Validation Loss: 2.037685
Validation loss decreased (1.914453 --&gt; 1.886676).  Saving model ...
Epoch: 12/100 	Training Loss: 1.905391 	Validation Loss: 2.019796
Epoch: 13/100 	Training Loss: 1.897869 	Validation Loss: 2.042009
Epoch: 14/100 	Training Loss: 1.917330 	Validation Loss: 2.069697
Epoch: 15/100 	Training Loss: 1.901373 	Validation Loss: 2.048057
Epoch: 16/100 	Training Loss: 1.931683 	Validation Loss: 2.079506
Epoch: 17/100 	Training Loss: 1.903681 	Validation Loss: 2.041736
Epoch: 18/100 	Training Loss: 1.905285 	Validation Loss: 2.064928
Epoch: 19/100 	Training Loss: 1.890572 	Validation Loss: 2.042564
Epoch: 20/100 	Training Loss: 1.891540 	Validation Loss: 2.040011
Epoch: 21/100 	Training Loss: 1.886099 	Validation Loss: 2.001538
Epoch: 22/100 	Training Loss: 1.892662 	Validation Loss: 2.043360
Epoch: 23/100 	Training Loss: 1.874153 	Validation Loss: 2.020605
Epoch: 24/100 	Training Loss: 1.887284 	Validation Loss: 2.037731
Epoch: 25/100 	Training Loss: 1.913565 	Validation Loss: 2.061414
Epoch: 26/100 	Training Loss: 1.895424 	Validation Loss: 2.036212
Epoch: 27/100 	Training Loss: 1.893901 	Validation Loss: 2.034571
Validation loss decreased (1.886676 --&gt; 1.861252).  Saving model ...
Epoch: 28/100 	Training Loss: 1.892401 	Validation Loss: 2.025984
Epoch: 29/100 	Training Loss: 1.881659 	Validation Loss: 2.034249
Epoch: 30/100 	Training Loss: 1.887723 	Validation Loss: 2.032261
Epoch: 31/100 	Training Loss: 1.877464 	Validation Loss: 2.030828
Epoch: 32/100 	Training Loss: 1.873735 	Validation Loss: 2.053210
Epoch: 33/100 	Training Loss: 1.892769 	Validation Loss: 2.062317
Epoch: 34/100 	Training Loss: 1.926907 	Validation Loss: 2.099619
Epoch: 35/100 	Training Loss: 1.913388 	Validation Loss: 2.057637
Epoch: 36/100 	Training Loss: 1.896660 	Validation Loss: 2.050619
Epoch: 37/100 	Training Loss: 1.885099 	Validation Loss: 2.043317
Epoch: 38/100 	Training Loss: 1.910708 	Validation Loss: 2.063756
Epoch: 39/100 	Training Loss: 1.892284 	Validation Loss: 2.031129
Epoch: 40/100 	Training Loss: 1.894769 	Validation Loss: 2.072907
Epoch: 41/100 	Training Loss: 1.916711 	Validation Loss: 2.111646
Epoch: 42/100 	Training Loss: 1.907748 	Validation Loss: 2.075157
Epoch: 43/100 	Training Loss: 1.902196 	Validation Loss: 2.080839
Epoch: 44/100 	Training Loss: 1.916238 	Validation Loss: 2.070233
Epoch: 45/100 	Training Loss: 1.906416 	Validation Loss: 2.048658
Epoch: 46/100 	Training Loss: 1.886834 	Validation Loss: 2.046270
Epoch: 47/100 	Training Loss: 1.896286 	Validation Loss: 2.053460
Epoch: 48/100 	Training Loss: 1.926351 	Validation Loss: 2.147960
Epoch: 49/100 	Training Loss: 1.916224 	Validation Loss: 2.073058
Epoch: 50/100 	Training Loss: 1.908418 	Validation Loss: 2.102307
Epoch: 51/100 	Training Loss: 1.909428 	Validation Loss: 2.060141
Epoch: 52/100 	Training Loss: 1.880711 	Validation Loss: 2.065563
Epoch: 53/100 	Training Loss: 1.897750 	Validation Loss: 2.060467
Epoch: 54/100 	Training Loss: 1.881901 	Validation Loss: 2.045987
Epoch: 55/100 	Training Loss: 1.892131 	Validation Loss: 2.038171
Epoch: 56/100 	Training Loss: 1.889707 	Validation Loss: 2.076825
Epoch: 57/100 	Training Loss: 1.884063 	Validation Loss: 2.069893
Epoch: 58/100 	Training Loss: 1.908220 	Validation Loss: 2.101316
Epoch: 59/100 	Training Loss: 1.920847 	Validation Loss: 2.072747
Epoch: 60/100 	Training Loss: 1.887903 	Validation Loss: 2.060806
Epoch: 61/100 	Training Loss: 1.894624 	Validation Loss: 2.060311
Epoch: 62/100 	Training Loss: 1.897483 	Validation Loss: 2.078270
Epoch: 63/100 	Training Loss: 1.892086 	Validation Loss: 2.062245
Epoch: 64/100 	Training Loss: 1.901208 	Validation Loss: 2.082479
Epoch: 65/100 	Training Loss: 1.917534 	Validation Loss: 2.073211
Epoch: 66/100 	Training Loss: 1.913353 	Validation Loss: 2.108092
Epoch: 67/100 	Training Loss: 1.915821 	Validation Loss: 2.083698
Epoch: 68/100 	Training Loss: 1.902871 	Validation Loss: 2.083377
Epoch: 69/100 	Training Loss: 1.899564 	Validation Loss: 2.066452
Epoch: 70/100 	Training Loss: 1.900696 	Validation Loss: 2.066603
Epoch: 71/100 	Training Loss: 1.900814 	Validation Loss: 2.076062
Epoch: 72/100 	Training Loss: 1.909731 	Validation Loss: 2.064871
Epoch: 73/100 	Training Loss: 1.910897 	Validation Loss: 2.080498
Epoch: 74/100 	Training Loss: 1.910500 	Validation Loss: 2.103350
Epoch: 75/100 	Training Loss: 1.930773 	Validation Loss: 2.107001
Epoch: 76/100 	Training Loss: 1.900320 	Validation Loss: 2.089695
Epoch: 77/100 	Training Loss: 1.914021 	Validation Loss: 2.110425
Epoch: 78/100 	Training Loss: 1.903375 	Validation Loss: 2.073662
Epoch: 79/100 	Training Loss: 1.904926 	Validation Loss: 2.083741
Epoch: 80/100 	Training Loss: 1.899218 	Validation Loss: 2.074880
Epoch: 81/100 	Training Loss: 1.893317 	Validation Loss: 2.086401
Epoch: 82/100 	Training Loss: 1.890393 	Validation Loss: 2.053685
Epoch: 83/100 	Training Loss: 1.882573 	Validation Loss: 2.084704
Epoch: 84/100 	Training Loss: 1.888510 	Validation Loss: 2.051252
Epoch: 85/100 	Training Loss: 1.890915 	Validation Loss: 2.089351
Epoch: 86/100 	Training Loss: 1.890093 	Validation Loss: 2.027609
Epoch: 87/100 	Training Loss: 1.883667 	Validation Loss: 2.055984
Epoch: 88/100 	Training Loss: 1.884753 	Validation Loss: 2.065890
Epoch: 89/100 	Training Loss: 1.900987 	Validation Loss: 2.082033
Epoch: 90/100 	Training Loss: 1.909990 	Validation Loss: 2.089382
Epoch: 91/100 	Training Loss: 1.918731 	Validation Loss: 2.092185
Epoch: 92/100 	Training Loss: 1.918806 	Validation Loss: 2.113726
Epoch: 93/100 	Training Loss: 1.929916 	Validation Loss: 2.084742
Epoch: 94/100 	Training Loss: 1.916393 	Validation Loss: 2.089705
Epoch: 95/100 	Training Loss: 1.916843 	Validation Loss: 2.088426
Validation loss decreased (1.861252 --&gt; 1.855618).  Saving model ...
Epoch: 96/100 	Training Loss: 1.906951 	Validation Loss: 2.084724
Epoch: 97/100 	Training Loss: 1.907536 	Validation Loss: 2.090133
Epoch: 98/100 	Training Loss: 1.898621 	Validation Loss: 2.082749
Epoch: 99/100 	Training Loss: 1.891242 	Validation Loss: 2.079129
Epoch: 100/100 	Training Loss: 1.912307 	Validation Loss: 2.096053
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">x</span>     <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
<span class="n">xi</span>    <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">epochs</span><span class="o">+</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">)]</span>
<span class="n">xi</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">f</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">f</span><span class="o">.</span><span class="n">set_figwidth</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">f</span><span class="o">.</span><span class="n">set_figheight</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">top</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">train_losses</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">valid_losses</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">best_epoch</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">xi</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Epochs&quot;</span><span class="p">,</span><span class="n">fontweight</span><span class="o">=</span><span class="s2">&quot;bold&quot;</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;Black&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;15&#39;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">,</span><span class="n">fontweight</span><span class="o">=</span><span class="s2">&quot;bold&quot;</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;Black&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;15&#39;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Losses (with Multi-Head Attention)&quot;</span><span class="p">,</span><span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;Black&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;15&#39;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Training Loss&quot;</span><span class="p">,</span><span class="s2">&quot;Valid Loss&quot;</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;Best Epoch= </span><span class="si">{</span><span class="n">best_epoch</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">])</span>


<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">tr_acc</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">val_acc</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">xi</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Epochs&quot;</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;Black&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;15&#39;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">,</span><span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;Black&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;15&#39;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Accuracies (with Multi-Head Attention)&quot;</span><span class="p">,</span><span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;Black&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;15&#39;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Training Accuracy&quot;</span><span class="p">,</span><span class="s2">&quot;Valid Accuracy&quot;</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Transformers_22_0.png" src="_images/Transformers_22_0.png" />
</div>
</div>
</section>
<section id="testing">
<h2>Testing<a class="headerlink" href="#testing" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">test_loader</span><span class="p">,</span><span class="n">net</span><span class="p">):</span>
    <span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">num_correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">valid_acc</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
        <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">inputs</span><span class="p">)[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">,:]</span>

        <span class="n">pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span> 
        <span class="n">top_value</span><span class="p">,</span> <span class="n">top_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">correct_tensor</span> <span class="o">=</span> <span class="n">top_index</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">top_index</span><span class="p">))</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">correct_tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
        <span class="n">num_correct</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">correct</span><span class="p">)</span>
    
    <span class="n">test_acc</span> <span class="o">=</span> <span class="n">num_correct</span><span class="o">/</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test accuracy: </span><span class="si">{:.3f}</span><span class="s2"> %&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_acc</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Transformer_Model</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">feed_fwd</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span><span class="n">n_head</span><span class="p">,</span> <span class="n">drop_prob</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;Trns_Multi_Att.pt&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;All keys matched successfully&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test</span><span class="p">(</span><span class="n">test_loader</span><span class="p">,</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test accuracy: 80.407 %
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="attention_2.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">GRU + Attention</p>
        </div>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Akshat Yadav<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>